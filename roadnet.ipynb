{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script summary\n",
    "- Import many xml files that were generated by the Send to Roadnet process in D365\n",
    "- Perform processing on the XML files, and import them into a Pandas dataframe containing outbound order lines from D365\n",
    "- Convert this into a dataframe that emulates the data that Roadnet would have returned - apply spec for every field in the file\n",
    "- Import a list of SessionIDs, one for each user (or virtual user) that will be importing and posting an inbound file from Roadnet\n",
    "- Split the inbound file (from Roadnet) into one file per SessionID\n",
    "- Export as CSV (take note lines must end with CR-NL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filenames\n",
    "consolidated_roadnet_out_file = 'data/roadnet/xml_consolidated/consolidated_roadnet_out.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the xml_prep folder\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)\n",
    "\n",
    "# Clean up the xml_consolidated folder\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert D365 XML outbound files from a single line (with no newlines) to multiple lines by inserting a newline after evert '>' character\n",
    "- Store the resulting files in the /xml_prep/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 12 XML files in  data/roadnet/xml_outbound/\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_outbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(\"Loading \" + str(len(dir_list)) + \" XML files in \", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_multiple_lines(fname, fnum):\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        # reading line by line\n",
    "        lines = fr.readlines()\n",
    "        last_line = len(lines)\n",
    "        #print(last_line)\n",
    "\n",
    "    for line in lines:\n",
    "        replaced_line = re.sub(\">\", \">\\u000A\", line)\n",
    "\n",
    "    outfile = 'data/roadnet/xml_prep/f'+str(fnum)+'.xml'\n",
    "\n",
    "    with open(outfile, 'w') as fw:\n",
    "        fw.write(replaced_line)    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert xml from D365 by adding newlines\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    #print(xml_file)\n",
    "    xml_to_multiple_lines(xml_file,i)\n",
    "\n",
    "number_of_xml = len(dir_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate the processed XML outbound files into a single, consolidated xml file\n",
    "- Remove all lines that are not transaction line items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "prep_dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_roadnet_files2(fname, fnum, outfile):\n",
    "\n",
    "    try:    \n",
    "        with open(fname, 'r') as fr:\n",
    "            # reading line by line\n",
    "            lines = fr.readlines()\n",
    "\n",
    "            last_line = len(lines)\n",
    "\n",
    "            # opening in writing mode\n",
    "            with open(outfile, 'a') as fw:\n",
    "                for line in lines:      \n",
    "                    substr1 = 'CCBROADNETWORKBENCHSESSIONTABLEENTITY'       \n",
    "                    x1 = re.search(substr1, line)\n",
    "                    substr2 = 'Document>'       \n",
    "                    x2 = re.search(substr2, line)\n",
    "                    substr3 = 'xml version='       \n",
    "                    x3 = re.search(substr3, line)\n",
    "                    #print(x)\n",
    "                    if x1 == None and x2 == None and x3 == None:\n",
    "                        fw.write(line)\n",
    "        #print(fname+\" lines deleted\")\n",
    "\n",
    "    except:\n",
    "        print(\"Error importing \"+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(prep_dir_list)):\n",
    "    xml_file = path+prep_dir_list[i]\n",
    "    #print(i)\n",
    "    #print(xml_file)\n",
    "    import_roadnet_files2(xml_file,i, consolidated_roadnet_out_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the consolidated xml file into 5,000 lines, else they cannot be imported into a Pandas dataframe\n",
    "- Store these files in the same folder as the consolidated xml, and delete the consolidated xml after the split\n",
    "- Add the lines to turn this into a valid XML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = consolidated_roadnet_out_file\n",
    "outfile = fname\n",
    "\n",
    "sizelimit = 5000\n",
    "\n",
    "try:    \n",
    "    with open(fname, 'r') as fr:\n",
    "        # reading line by line\n",
    "        lines = fr.readlines()\n",
    "\n",
    "        last_line = len(lines)\n",
    "\n",
    "        line_counter = 1\n",
    "\n",
    "        # opening in writing mode\n",
    "        last_x = 0\n",
    "        for i in range(0,len(lines)):\n",
    "            line = lines[i]\n",
    "            if i == last_line:\n",
    "                print(line)\n",
    "            x = int(i/sizelimit)\n",
    "            with open(outfile[:-4]+str(x)+'.xml', 'a') as fw:        \n",
    "                if i == 0:\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                if x > last_x:\n",
    "                    last_x = x\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                fw.write(line)\n",
    "                if int((i+1)/sizelimit) > x:\n",
    "                    fw.write('</Document>')\n",
    "                if i == len(lines) - 1:\n",
    "                    fw.write('</Document>')\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "                \n",
    "except:\n",
    "    print(\"Error importing \"+fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the transformed XML files into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "#print(\"Files and directories in '\", path, \"' :\")\n",
    "\n",
    "# prints all files\n",
    "#print(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the first file into a dataframe\n",
    "rdnet_out = pd.read_xml(path+dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the rest of the files, and append to the dataframe\n",
    "for i in range(1,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    print(str(i)+xml_file)\n",
    "    temp = pd.read_xml(path+dir_list[i])\n",
    "    rdnet_out = pd.concat([rdnet_out, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INVENTTRANSID</th>\n",
       "      <th>BLOCKEDSTATUS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>CREDITRELEASEDATE</th>\n",
       "      <th>CREDITRELEASETIME</th>\n",
       "      <th>DAILYURGENCYINCREASE</th>\n",
       "      <th>DEPENDENCY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>DYNAMICSINTERNALSESSIONID</th>\n",
       "      <th>ERROR</th>\n",
       "      <th>...</th>\n",
       "      <th>REFTABLEID</th>\n",
       "      <th>ROADNETROUTE</th>\n",
       "      <th>SALESMANAGER</th>\n",
       "      <th>SHIPDATE</th>\n",
       "      <th>URGENCY</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>WAREHOUSEDESC</th>\n",
       "      <th>WAREHOUSEID</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>WEIGHTUNIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>UG1-000982</td>\n",
       "      <td>0</td>\n",
       "      <td>Katabi-Entebbe</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IMPERIAL GOLF VIEW HOTEL</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>13.62</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>UG1-000924</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GLOBAL CENTER LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>84.00</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>UG1-001001</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GLOBAL CENTER LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>5.00</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>UG1-000902</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CAFE JAVAS LTD</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>6.72</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>UG1-000944</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CAFE JAVAS LTD</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>50.40</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>UG1-000893</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIRWAY HOTEL LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>6.72</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>UG1-000983</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIRWAY HOTEL LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>57.60</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>UG1-000982</td>\n",
       "      <td>0</td>\n",
       "      <td>Katabi-Entebbe</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IMPERIAL GOLF VIEW HOTEL</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>13.62</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>UG1-000924</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GLOBAL CENTER LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>84.00</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>UG1-001001</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GLOBAL CENTER LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>5.00</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>UG1-000902</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CAFE JAVAS LTD</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>6.72</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>UG1-000944</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CAFE JAVAS LTD</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>50.40</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>UG1-000893</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIRWAY HOTEL LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>6.72</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>UG1-000983</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FAIRWAY HOTEL LIMITED</td>\n",
       "      <td>UG1-010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>UG010B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-10T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mbarara Quarantine WH</td>\n",
       "      <td>UG011Q</td>\n",
       "      <td>57.60</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    INVENTTRANSID  BLOCKEDSTATUS            CITY          CREDITRELEASEDATE  \\\n",
       "244    UG1-000982              0  Katabi-Entebbe  1900-01-01T00:00:00+00:00   \n",
       "245    UG1-000924              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "246    UG1-001001              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "247    UG1-000902              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "248    UG1-000944              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "249    UG1-000893              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "250    UG1-000983              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "310    UG1-000982              0  Katabi-Entebbe  1900-01-01T00:00:00+00:00   \n",
       "311    UG1-000924              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "312    UG1-001001              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "313    UG1-000902              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "314    UG1-000944              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "315    UG1-000893              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "316    UG1-000983              0             NaN  1900-01-01T00:00:00+00:00   \n",
       "\n",
       "     CREDITRELEASETIME  DAILYURGENCYINCREASE  DEPENDENCY  \\\n",
       "244                  0                     0           0   \n",
       "245                  0                     0           0   \n",
       "246                  0                     0           0   \n",
       "247                  0                     0           0   \n",
       "248                  0                     0           0   \n",
       "249                  0                     0           0   \n",
       "250                  0                     0           0   \n",
       "310                  0                     0           0   \n",
       "311                  0                     0           0   \n",
       "312                  0                     0           0   \n",
       "313                  0                     0           0   \n",
       "314                  0                     0           0   \n",
       "315                  0                     0           0   \n",
       "316                  0                     0           0   \n",
       "\n",
       "                  DESCRIPTION DYNAMICSINTERNALSESSIONID  ERROR  ...  \\\n",
       "244  IMPERIAL GOLF VIEW HOTEL                   UG1-010    NaN  ...   \n",
       "245     GLOBAL CENTER LIMITED                   UG1-010    NaN  ...   \n",
       "246     GLOBAL CENTER LIMITED                   UG1-010    NaN  ...   \n",
       "247            CAFE JAVAS LTD                   UG1-010    NaN  ...   \n",
       "248            CAFE JAVAS LTD                   UG1-010    NaN  ...   \n",
       "249     FAIRWAY HOTEL LIMITED                   UG1-010    NaN  ...   \n",
       "250     FAIRWAY HOTEL LIMITED                   UG1-010    NaN  ...   \n",
       "310  IMPERIAL GOLF VIEW HOTEL                   UG1-010    NaN  ...   \n",
       "311     GLOBAL CENTER LIMITED                   UG1-010    NaN  ...   \n",
       "312     GLOBAL CENTER LIMITED                   UG1-010    NaN  ...   \n",
       "313            CAFE JAVAS LTD                   UG1-010    NaN  ...   \n",
       "314            CAFE JAVAS LTD                   UG1-010    NaN  ...   \n",
       "315     FAIRWAY HOTEL LIMITED                   UG1-010    NaN  ...   \n",
       "316     FAIRWAY HOTEL LIMITED                   UG1-010    NaN  ...   \n",
       "\n",
       "     REFTABLEID  ROADNETROUTE SALESMANAGER                   SHIPDATE  \\\n",
       "244        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "245        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "246        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "247        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "248        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "249        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "250        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "310        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "311        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "312        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "313        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "314        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "315        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "316        1328      UG010B01          NaN  2023-10-10T00:00:00+00:00   \n",
       "\n",
       "     URGENCY  VOLUME          WAREHOUSEDESC  WAREHOUSEID WEIGHT WEIGHTUNIT  \n",
       "244        0     0.0  Mbarara Quarantine WH       UG011Q  13.62         CS  \n",
       "245        0     0.0  Mbarara Quarantine WH       UG011Q  84.00         CS  \n",
       "246        0     0.0  Mbarara Quarantine WH       UG011Q   5.00         CS  \n",
       "247        0     0.0  Mbarara Quarantine WH       UG011Q   6.72         CS  \n",
       "248        0     0.0  Mbarara Quarantine WH       UG011Q  50.40         CS  \n",
       "249        0     0.0  Mbarara Quarantine WH       UG011Q   6.72         CS  \n",
       "250        0     0.0  Mbarara Quarantine WH       UG011Q  57.60         CS  \n",
       "310        0     0.0  Mbarara Quarantine WH       UG011Q  13.62         CS  \n",
       "311        0     0.0  Mbarara Quarantine WH       UG011Q  84.00         CS  \n",
       "312        0     0.0  Mbarara Quarantine WH       UG011Q   5.00         CS  \n",
       "313        0     0.0  Mbarara Quarantine WH       UG011Q   6.72         CS  \n",
       "314        0     0.0  Mbarara Quarantine WH       UG011Q  50.40         CS  \n",
       "315        0     0.0  Mbarara Quarantine WH       UG011Q   6.72         CS  \n",
       "316        0     0.0  Mbarara Quarantine WH       UG011Q  57.60         CS  \n",
       "\n",
       "[14 rows x 40 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdnet_out[rdnet_out.duplicated(['INVENTTRANSID'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_out.drop(columns={'OUTPERFORMROADNETDESTINATION'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_out = rdnet_out.drop_duplicates(keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Roadnet inbound file by copying selected columns as-is from the outbound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_out[['QUANTITY','LOCATIONID','INVENTTRANSID','ITEMID','ORDERID','WAREHOUSEID','PRODUCTNAME','ROADNETROUTE','ORDERACCOUNT','ORDERACCOUNTNAME','WEIGHT']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_in.dropna(subset=['WAREHOUSEID']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'QUANTITY':'CASEQTY','LOCATIONID':'DESTINATIONLOCATIONID','ORDERID':'ORDERNUMBER','WAREHOUSEID':'ORIGINLOCATIONID','ORDERACCOUNT':'STOPLOCATIONID','ORDERACCOUNTNAME':'STOPLOCATIONNAME'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the rest of the fields as per the Roadnet inbound file spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.now())\n",
    "today = today.replace(':','h')\n",
    "today = today.replace('-','')\n",
    "today = today.replace(' ','-')\n",
    "today = today[0:14] + '-'\n",
    "#print(\"Today date is: \", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROADNETROUTEINTERNALROUTEID'] = today + rdnet_in['STOPLOCATIONID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_customers = len(rdnet_in['STOPLOCATIONID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get legal entity from the invettransid\n",
    "le_code = rdnet_in.loc[0, 'INVENTTRANSID'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults applied to all LEs\n",
    "\n",
    "rdnet_in['APPTID'] = ''\n",
    "rdnet_in['ERROR'] = ''\n",
    "rdnet_in['LASTSTOPISDESTINATION'] = 'No'\n",
    "rdnet_in['LOADID'] = ''\n",
    "rdnet_in['LOADTEMPLATEID'] = ''\n",
    "rdnet_in['ORDERTYPE'] = 'rotOrder'\n",
    "rdnet_in['ORIGINDESTINATION'] = 'Yes'\n",
    "rdnet_in['PALLETQTY'] = '0'\n",
    "rdnet_in['REFERENCECATEGORY'] = 'Sales'\n",
    "rdnet_in['REFERENCEDOCUMENT'] = 'SalesOrder'\n",
    "rdnet_in['ROADNETINTERNALSESSIONID'] = '35411'\n",
    "rdnet_in['ROADNETREGIONID'] = le_code\n",
    "rdnet_in['ROUTECODE'] = ''\n",
    "rdnet_in['SECONDDRIVER'] = ''\n",
    "rdnet_in['SECONDTRAILER'] = ''\n",
    "rdnet_in['SEQUENCEDISTANCE'] = '.000000'\n",
    "rdnet_in['SEQUENCENUMBER'] = '1'\n",
    "rdnet_in['SEQUENCETRAVELTIME'] = '0'\n",
    "rdnet_in['STATUS'] = 'Error'\n",
    "rdnet_in['STOPTYPE'] = 'stpStop'\n",
    "rdnet_in['TOTALDISTANCE'] = '.000000'\n",
    "rdnet_in['TOTALROUTEDISTANCE'] = '.000000'\n",
    "rdnet_in['TRUCKANDTRAILERASSIGNED'] = 'No'\n",
    "rdnet_in['UNITID'] = ''\n",
    "rdnet_in['STOPSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALTRAVELTIME'] = '0'\n",
    "rdnet_in['LINEREFID'] = rdnet_in['INVENTTRANSID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults that are specific per LE\n",
    "\n",
    "if le_code == \"ZA1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'BLOEM_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = '825196'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'ST29PTAIL'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "    rdnet_in['VEHICLEID'] = 'TT4X2TAIL'\n",
    "\n",
    "elif le_code == \"NA1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'Windhoek_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = 'NA1-000002'\n",
    "    #rdnet_in['FIRSTTRAILER'] = 'LD1001'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'TT1001'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "    #rdnet_in['VEHICLEID'] = 'LD1002'\n",
    "    rdnet_in['VEHICLEID'] = 'TT1002'\n",
    "\n",
    "elif le_code == \"UG1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'Rwenzori_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = 'UG1-000001'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'TT1003'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = 'INTERNAL'\n",
    "    rdnet_in['VEHICLEID'] = 'TT1004'    \n",
    "    \n",
    "elif le_code == \"MZ1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'Chimoio_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = 'MZ1-000001'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'TT1002'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "    rdnet_in['VEHICLEID'] = 'TT1003'    \n",
    "    \n",
    "else:\n",
    "    print(\"No valid legal entity\")\n",
    "    raise SystemExit(\"Terminating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_txt = input('Enter the dispatch date in the format yyyy-mm-dd: ')\n",
    "date_dt = pd.to_datetime(date_txt)\n",
    "#date_dt = pd.to_datetime('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROUTECOMPLETETIME'] = date_dt\n",
    "rdnet_in['ROUTECOMPLETETIME'] = rdnet_in['ROUTECOMPLETETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=13) + pd.Timedelta(minutes=19)\n",
    "\n",
    "rdnet_in['ROUTESTARTTIME'] = date_dt\n",
    "rdnet_in['ROUTESTARTTIME'] = rdnet_in['ROUTESTARTTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = rdnet_in['SCHEDULEDARRIVALDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=12) + pd.Timedelta(minutes=59)\n",
    "\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = rdnet_in['SCHEDULEDDELIVERYDATETIME'].dt.normalize() + pd.Timedelta(days=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = rdnet_in['SCHEDULEDSHIPDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=10)\n",
    "\n",
    "rdnet_in['STOPARRIVALTIME'] = date_dt\n",
    "rdnet_in['STOPARRIVALTIME'] = rdnet_in['STOPARRIVALTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=8) + pd.Timedelta(minutes=28)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get customer master in order to get the postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the customer master to obtain the zipcode\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the customer master to obtain the zipcode\")\n",
    "\n",
    "if le_code == \"ZA1\":\n",
    "    #Do the following once-off to create the parquet file\n",
    "    #customers=pd.read_csv(\"./data/customers/2023-08-10_CustomersV3.csv\",low_memory=False)\n",
    "    #customers.to_parquet(\"./data/customers.parquet\")\n",
    "    customers=pd.read_parquet(\"./data/customers/customers.parquet\")\n",
    "    #customers_short = customers[['ADDRESSZIPCODE','CUSTOMERACCOUNT','ORGANIZATIONNAME']].copy()\n",
    "\n",
    "elif le_code == \"NA1\" or le_code == \"UG1\" or le_code == \"MZ1\":\n",
    "    customers=pd.read_csv(\"./data/customers/NA1_UG1_MZ1_Export-Customersaddresses V3.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid customer master file\")\n",
    "    raise SystemExit(\"Terminating\")\n",
    "    \n",
    "\n",
    "customers_short = customers[['ADDRESSZIPCODE','CUSTOMERACCOUNT']].copy()\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].fillna(0)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(int)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in_bk=rdnet_in.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    customers_short,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='STOPLOCATIONID',\n",
    "    right_on='CUSTOMERACCOUNT',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'ADDRESSZIPCODE':'STOPPOSTALCODE'}, inplace=True)\n",
    "rdnet_in.drop(columns={'CUSTOMERACCOUNT'}, inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split file into n files, each with a different ORIGINLOCATIONID\n",
    "- Read csv file with ORIGINLOCATIONIDs\n",
    "- Generate a dataframe with the unique list of warehouses\n",
    "- Add a column (Group) to that dataframe where the warehouses are assigned into n groups\n",
    "- Generate n output files, each with ORIGINLOCATIONID as from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input('Remember to update data/roadnet/sessionIDs.csv with the list of session IDs.  This will determine how the Roadnet inbound file will be split.  Press \"Enter\" to continue. ')\n",
    "sessionids = pd.read_csv('data/roadnet/sessionIDs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting inbound files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting inbound files per sessionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionids_list = sessionids.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_warehouses_np = rdnet_in['ORIGINLOCATIONID'].unique()\n",
    "unique_warehouses_df = pd.DataFrame(unique_warehouses_np)\n",
    "number_of_warehouses = len(rdnet_in['ORIGINLOCATIONID'].unique())\n",
    "number_of_sessionIDs = len(sessionids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_warehouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_of_warehouses < number_of_sessionIDs:\n",
    "    raise SystemExit(\"There are more sessionIDs than warehouses - some of the output files will have no lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['WH_route_combination'] = rdnet_in['ORIGINLOCATIONID'].astype(str) + rdnet_in['ROADNETROUTE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rdnet_in.groupby(['WH_route_combination']).agg({'INVENTTRANSID': 'count'}).sort_values('INVENTTRANSID',ascending=False).reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['sessionID'] = ''\n",
    "user = 0\n",
    "user_ascending = True\n",
    "for i in range(len(x)):\n",
    "    if user_ascending == True and user < number_of_sessionIDs:\n",
    "        user = user + 1\n",
    "\n",
    "    if user_ascending == False and user <= number_of_sessionIDs:\n",
    "        if user > 1:\n",
    "            user = user - 1\n",
    "        else:\n",
    "            user = number_of_sessionIDs\n",
    "\n",
    "    if user_ascending == True and user == number_of_sessionIDs:\n",
    "        user_ascending = False\n",
    "        user = number_of_sessionIDs           \n",
    "\n",
    "    x.at[i, 'sessionID'] = str(sessionids_list[user-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(columns={'INVENTTRANSID'}, inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge back the warehouse-based split into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    x,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='WH_route_combination',\n",
    "    right_on='WH_route_combination',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.drop(columns={'WH_route_combination'}, inplace=True, axis=1)\n",
    "rdnet_in.rename(columns={'sessionID':'DYNAMICSRETRIEVALSESSIONID'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing CSV files per sessionID\")\n",
    "# Clean up the folder where the inbound files are to be stored\n",
    "path = \"data/roadnet/inbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sessionID in sessionids_list:\n",
    "    mask = (rdnet_in['DYNAMICSRETRIEVALSESSIONID'] == sessionID[0])\n",
    "    df_temp = rdnet_in[mask].copy()\n",
    "    filename = 'data/roadnet/inbound/rdnet_inbound_'+sessionID[0]\n",
    "    df_temp.to_csv(filename+'.csv',index=False, lineterminator='\\r\\n')    \n",
    "    df_temp.to_xml(filename+'.xml',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Roadnet order lines were split by warehouse and route ID, into 3 files.  The lines were split as follows:\n",
      "                            INVENTTRANSID\n",
      "DYNAMICSRETRIEVALSESSIONID               \n",
      "UG1-001                               117\n",
      "UG1-002                                30\n",
      "UG1-003                                15\n"
     ]
    }
   ],
   "source": [
    "print('The Roadnet order lines were split by warehouse and route ID, into ' + str(number_of_sessionIDs) + ' files.  The lines were split as follows:')\n",
    "print(rdnet_in.groupby(['DYNAMICSRETRIEVALSESSIONID']).agg({'INVENTTRANSID': 'count'}))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
