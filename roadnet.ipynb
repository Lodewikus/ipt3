{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script summary\n",
    "- Import many xml files that were generated by the Send to Roadnet process in D365\n",
    "- Perform processing on the XML files, and import them into a Pandas dataframe containing outbound order lines from D365\n",
    "- Convert this into a dataframe that emulates the data that Roadnet would have returned - apply spec for every field in the file\n",
    "- Import a list of SessionIDs, one for each user (or virtual user) that will be importing and posting an inbound file from Roadnet\n",
    "- Split the inbound file (from Roadnet) into one file per SessionID\n",
    "- Export as CSV (take note lines must end with CR-NL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filenames\n",
    "consolidated_roadnet_out_file = 'data/roadnet/xml_consolidated/consolidated_roadnet_out.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the xml_prep folder\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)\n",
    "\n",
    "# Clean up the xml_consolidated folder\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert D365 XML outbound files from a single line (with no newlines) to multiple lines by inserting a newline after evert '>' character\n",
    "- Store the resulting files in the /xml_prep/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 12 XML files in  data/roadnet/xml_outbound/\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_outbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(\"Loading \" + str(len(dir_list)) + \" XML files in \", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_multiple_lines(fname, fnum):\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        lines = fr.readlines()\n",
    "        last_line = len(lines)\n",
    "\n",
    "    for line in lines:\n",
    "        #replaced_line = re.sub(\">\", \">\\u000A\", line)\n",
    "        replaced_line = re.sub(\">\", \">\\n\", line)\n",
    "\n",
    "    outfile = 'data/roadnet/xml_prep/f'+str(fnum)+'.xml'\n",
    "\n",
    "    with open(outfile, 'w') as fw:\n",
    "        fw.write(replaced_line)    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert xml from D365 by adding newlines\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    xml_to_multiple_lines(xml_file,i)\n",
    "\n",
    "number_of_xml = len(dir_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate the processed XML outbound files into a single, consolidated xml file\n",
    "- Remove all lines that are not transaction line items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "prep_dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_code = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_roadnet_files2(fname, fnum, outfile):\n",
    "\n",
    "    try:    \n",
    "        with open(fname, 'r') as fr:\n",
    "            lines = fr.readlines()\n",
    "\n",
    "            last_line = len(lines)\n",
    "\n",
    "            with open(outfile, 'a') as fw:\n",
    "                i = 0\n",
    "                for line in lines:      \n",
    "                    i = i + 1\n",
    "                    substr_le = 'LE_ID=\"ug1\"'       \n",
    "                    le11 = re.search(substr_le, line)\n",
    "                    print(le11)\n",
    "                    substr_le = 'LE_ID=\"UG1\"'\n",
    "                    le12 = re.search(substr_le, line)\n",
    "                    substr_le = 'LE_ID=\"mz1\"'       \n",
    "                    le21 = re.search(substr_le, line)\n",
    "                    substr_le = 'LE_ID=\"MZ1\"'\n",
    "                    le22 = re.search(substr_le, line)                    \n",
    "                    substr_le = 'LE_ID=\"na1\"'       \n",
    "                    le31 = re.search(substr_le, line)\n",
    "                    substr_le = 'LE_ID=\"NA1\"'\n",
    "                    le32 = re.search(substr_le, line)                    \n",
    "\n",
    "                    if le11 != None or le12 != None:\n",
    "                        le_code = 'UG1'\n",
    "                    if le21 != None or le22 != None:\n",
    "                        le_code = 'MZ1'                        \n",
    "                    if le31 != None or le32 != None:\n",
    "                        le_code = 'NA1'                        \n",
    "\n",
    "                    substr1 = 'CCBROADNETWORKBENCHSESSIONTABLEENTITY'       \n",
    "                    x1 = re.search(substr1, line)\n",
    "                    substr2 = 'Document>'       \n",
    "                    x2 = re.search(substr2, line)\n",
    "                    substr3 = 'xml version='       \n",
    "                    x3 = re.search(substr3, line)\n",
    "                    if x1 == None and x2 == None and x3 == None:\n",
    "                        fw.write(line)\n",
    "        return le_code\n",
    "            \n",
    "    except:\n",
    "        print(\"Error importing \"+fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(312, 323), match='LE_ID=\"ug1\"'>\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(prep_dir_list)):\n",
    "    xml_file = path+prep_dir_list[i]\n",
    "    le_code = import_roadnet_files2(xml_file,i, consolidated_roadnet_out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UG1'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the consolidated xml file into 5,000 lines, else they cannot be imported into a Pandas dataframe\n",
    "- Store these files in the same folder as the consolidated xml, and delete the consolidated xml after the split\n",
    "- Add the lines to turn this into a valid XML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = consolidated_roadnet_out_file\n",
    "outfile = fname\n",
    "\n",
    "sizelimit = 5000\n",
    "\n",
    "try:    \n",
    "    with open(fname, 'r') as fr:\n",
    "        lines = fr.readlines()\n",
    "\n",
    "        last_line = len(lines)\n",
    "\n",
    "        line_counter = 1\n",
    "\n",
    "        last_x = 0\n",
    "        for i in range(0,len(lines)):\n",
    "            line = lines[i]\n",
    "            if i == last_line:\n",
    "                print(line)\n",
    "            x = int(i/sizelimit)\n",
    "            with open(outfile[:-4]+str(x)+'.xml', 'a') as fw:        \n",
    "                if i == 0:\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                if x > last_x:\n",
    "                    last_x = x\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                fw.write(line)\n",
    "                if int((i+1)/sizelimit) > x:\n",
    "                    fw.write('</Document>')\n",
    "                if i == len(lines) - 1:\n",
    "                    fw.write('</Document>')\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "                \n",
    "except:\n",
    "    print(\"Error importing \"+fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the transformed XML files into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "#print(\"Files and directories in '\", path, \"' :\")\n",
    "\n",
    "# prints all files\n",
    "#print(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the first file into a dataframe\n",
    "rdnet_out = pd.read_xml(path+dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the rest of the files, and append to the dataframe\n",
    "for i in range(1,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    print(str(i)+xml_file)\n",
    "    temp = pd.read_xml(path+dir_list[i])\n",
    "    rdnet_out = pd.concat([rdnet_out, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_out.drop(columns={'OUTPERFORMROADNETDESTINATION'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_out = rdnet_out.drop_duplicates(keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Roadnet inbound file by copying selected columns as-is from the outbound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_out[['QUANTITY','LOCATIONID','INVENTTRANSID','ITEMID','ORDERID','WAREHOUSEID','PRODUCTNAME','ROADNETROUTE','ORDERACCOUNT','ORDERACCOUNTNAME','WEIGHT']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_in.dropna(subset=['WAREHOUSEID']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'QUANTITY':'CASEQTY','LOCATIONID':'DESTINATIONLOCATIONID','ORDERID':'ORDERNUMBER','WAREHOUSEID':'ORIGINLOCATIONID','ORDERACCOUNT':'STOPLOCATIONID','ORDERACCOUNTNAME':'STOPLOCATIONNAME'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the rest of the fields as per the Roadnet inbound file spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.now())\n",
    "today = today.replace(':','h')\n",
    "today = today.replace('-','')\n",
    "today = today.replace(' ','-')\n",
    "today = today[0:14] + '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROADNETROUTEINTERNALROUTEID'] = today + rdnet_in['STOPLOCATIONID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_customers = len(rdnet_in['STOPLOCATIONID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get legal entity from the invettransid\n",
    "if le_code == \"\":\n",
    "    le_code = rdnet_in.loc[0, 'INVENTTRANSID'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults applied to all LEs\n",
    "\n",
    "rdnet_in['APPTID'] = ''\n",
    "rdnet_in['ERROR'] = ''\n",
    "rdnet_in['LASTSTOPISDESTINATION'] = 'No'\n",
    "rdnet_in['LOADID'] = ''\n",
    "rdnet_in['LOADTEMPLATEID'] = ''\n",
    "rdnet_in['ORDERTYPE'] = 'rotOrder'\n",
    "rdnet_in['ORIGINDESTINATION'] = 'Yes'\n",
    "rdnet_in['PALLETQTY'] = '0'\n",
    "rdnet_in['REFERENCECATEGORY'] = 'Sales'\n",
    "rdnet_in['REFERENCEDOCUMENT'] = 'SalesOrder'\n",
    "rdnet_in['ROADNETINTERNALSESSIONID'] = '35411'\n",
    "rdnet_in['ROADNETREGIONID'] = le_code\n",
    "rdnet_in['ROUTECODE'] = ''\n",
    "rdnet_in['SECONDDRIVER'] = ''\n",
    "rdnet_in['SECONDTRAILER'] = ''\n",
    "rdnet_in['SEQUENCEDISTANCE'] = '.000000'\n",
    "rdnet_in['SEQUENCENUMBER'] = '1'\n",
    "rdnet_in['SEQUENCETRAVELTIME'] = '0'\n",
    "rdnet_in['STATUS'] = 'Error'\n",
    "rdnet_in['STOPTYPE'] = 'stpStop'\n",
    "rdnet_in['TOTALDISTANCE'] = '.000000'\n",
    "rdnet_in['TOTALROUTEDISTANCE'] = '.000000'\n",
    "rdnet_in['TRUCKANDTRAILERASSIGNED'] = 'No'\n",
    "rdnet_in['UNITID'] = ''\n",
    "rdnet_in['STOPSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALTRAVELTIME'] = '0'\n",
    "rdnet_in['LINEREFID'] = rdnet_in['INVENTTRANSID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults that are specific per LE\n",
    "\n",
    "if le_code == \"ZA1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'BLOEM_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = '825196'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'ST29PTAIL'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "    rdnet_in['VEHICLEID'] = 'TT4X2TAIL'\n",
    "\n",
    "elif le_code == \"NA1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'Windhoek_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = 'NA1-000002'\n",
    "    #rdnet_in['FIRSTTRAILER'] = 'LD1001'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'TT1001'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "    #rdnet_in['VEHICLEID'] = 'LD1002'\n",
    "    rdnet_in['VEHICLEID'] = 'TT1002'\n",
    "\n",
    "elif le_code == \"UG1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'Rwenzori_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = 'UG1-000001'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'TT1003'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = 'INTERNAL'\n",
    "    rdnet_in['VEHICLEID'] = 'TT1004'    \n",
    "    \n",
    "elif le_code == \"MZ1\":\n",
    "    rdnet_in['DESCRIPTION'] = 'Chimoio_PLAN'\n",
    "    rdnet_in['FIRSTDRIVER'] = 'MZ1-000001'\n",
    "    rdnet_in['FIRSTTRAILER'] = 'TT1002'\n",
    "    rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "    rdnet_in['VEHICLEID'] = 'TT1003'    \n",
    "    \n",
    "else:\n",
    "    print(\"No valid legal entity\")\n",
    "    raise SystemExit(\"Terminating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_trucks = pd.read_excel('data/roadnet/drivers_trucks.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_trucks = drivers_trucks[drivers_trucks['le_code'] == le_code].reset_index(drop=True).copy()\n",
    "drivers_trucks_len = len(drivers_trucks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_locations = rdnet_in['STOPLOCATIONID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_in.sort_values(by=['STOPLOCATIONID']).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "truck_index = 1\n",
    "for stop_location in stop_locations:\n",
    "    if truck_index > drivers_trucks_len:\n",
    "        truck_index = 1\n",
    "    for index, row in rdnet_in[rdnet_in['STOPLOCATIONID'] == stop_location].iterrows():\n",
    "        rdnet_in.loc[index, ['FIRSTDRIVER']] = drivers_trucks.loc[truck_index - 1, ['FIRSTDRIVER']]\n",
    "        rdnet_in.loc[index, ['FIRSTTRAILER']] = drivers_trucks.loc[truck_index - 1, ['FIRSTTRAILER']]\n",
    "        rdnet_in.loc[index, ['VEHICLEID']] = drivers_trucks.loc[truck_index - 1, ['VEHICLEID']]\n",
    "    truck_index = truck_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_txt = input('Enter the dispatch date in the format yyyy-mm-dd: ')\n",
    "date_dt = pd.to_datetime(date_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROUTECOMPLETETIME'] = date_dt\n",
    "rdnet_in['ROUTECOMPLETETIME'] = rdnet_in['ROUTECOMPLETETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=13) + pd.Timedelta(minutes=19)\n",
    "\n",
    "rdnet_in['ROUTESTARTTIME'] = date_dt\n",
    "rdnet_in['ROUTESTARTTIME'] = rdnet_in['ROUTESTARTTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = rdnet_in['SCHEDULEDARRIVALDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=12) + pd.Timedelta(minutes=59)\n",
    "\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = rdnet_in['SCHEDULEDDELIVERYDATETIME'].dt.normalize() + pd.Timedelta(days=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = rdnet_in['SCHEDULEDSHIPDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=10)\n",
    "\n",
    "rdnet_in['STOPARRIVALTIME'] = date_dt\n",
    "rdnet_in['STOPARRIVALTIME'] = rdnet_in['STOPARRIVALTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=8) + pd.Timedelta(minutes=28)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get customer master in order to get the postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the customer master to obtain the zipcode\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the customer master to obtain the zipcode\")\n",
    "\n",
    "if le_code == \"ZA1\":\n",
    "    customers=pd.read_parquet(\"./data/customers/customers.parquet\")\n",
    "\n",
    "elif le_code == \"NA1\" or le_code == \"UG1\" or le_code == \"MZ1\":\n",
    "    customers=pd.read_csv(\"./data/customers/roa_customers.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid customer master file\")\n",
    "    raise SystemExit(\"Terminating\")\n",
    "    \n",
    "\n",
    "customers_short = customers[['ADDRESSZIPCODE','CUSTOMERACCOUNT']].copy()\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].fillna(0)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(int)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in_bk=rdnet_in.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    customers_short,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='STOPLOCATIONID',\n",
    "    right_on='CUSTOMERACCOUNT',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'ADDRESSZIPCODE':'STOPPOSTALCODE'}, inplace=True)\n",
    "rdnet_in.drop(columns={'CUSTOMERACCOUNT'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split file into n files, each with a different ORIGINLOCATIONID\n",
    "- Read csv file with ORIGINLOCATIONIDs\n",
    "- Generate a dataframe with the unique list of warehouses\n",
    "- Add a column (Group) to that dataframe where the warehouses are assigned into n groups\n",
    "- Generate n output files, each with ORIGINLOCATIONID as from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input('Remember to update data/roadnet/sessionIDs.csv with the list of session IDs.  This will determine how the Roadnet inbound file will be split.  Press \"Enter\" to continue. ')\n",
    "sessionids = pd.read_csv('data/roadnet/sessionIDs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting inbound files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting inbound files per sessionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionids_list = sessionids.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_warehouses_np = rdnet_in['ORIGINLOCATIONID'].unique()\n",
    "unique_warehouses_df = pd.DataFrame(unique_warehouses_np)\n",
    "number_of_warehouses = len(rdnet_in['ORIGINLOCATIONID'].unique())\n",
    "number_of_sessionIDs = len(sessionids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_warehouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_of_warehouses < number_of_sessionIDs:\n",
    "    raise SystemExit(\"There are more sessionIDs than warehouses - some of the output files will have no lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['WH_route_combination'] = rdnet_in['ORIGINLOCATIONID'].astype(str) + rdnet_in['ROADNETROUTE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rdnet_in.groupby(['WH_route_combination']).agg({'INVENTTRANSID': 'count'}).sort_values('INVENTTRANSID',ascending=False).reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['sessionID'] = ''\n",
    "user = 0\n",
    "user_ascending = True\n",
    "for i in range(len(x)):\n",
    "    if user_ascending == True and user < number_of_sessionIDs:\n",
    "        user = user + 1\n",
    "\n",
    "    if user_ascending == False and user <= number_of_sessionIDs:\n",
    "        if user > 1:\n",
    "            user = user - 1\n",
    "        else:\n",
    "            user = number_of_sessionIDs\n",
    "\n",
    "    if user_ascending == True and user == number_of_sessionIDs:\n",
    "        user_ascending = False\n",
    "        user = number_of_sessionIDs           \n",
    "\n",
    "    x.at[i, 'sessionID'] = str(sessionids_list[user-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(columns={'INVENTTRANSID'}, inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge back the warehouse-based split into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    x,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='WH_route_combination',\n",
    "    right_on='WH_route_combination',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.drop(columns={'WH_route_combination'}, inplace=True, axis=1)\n",
    "rdnet_in.rename(columns={'sessionID':'DYNAMICSRETRIEVALSESSIONID'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing CSV files per sessionID\")\n",
    "# Clean up the folder where the inbound files are to be stored\n",
    "path = \"data/roadnet/inbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sessionID in sessionids_list:\n",
    "    mask = (rdnet_in['DYNAMICSRETRIEVALSESSIONID'] == sessionID[0])\n",
    "    df_temp = rdnet_in[mask].copy()\n",
    "    filename = 'data/roadnet/inbound/rdnet_inbound_'+sessionID[0]\n",
    "    df_temp.to_csv(filename+'.csv',index=False, lineterminator='\\r\\n')    \n",
    "    df_temp.to_xml(filename+'.xml',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Roadnet order lines were split by warehouse and route ID, into 3 files.  The lines were split as follows:\n",
      "                            INVENTTRANSID\n",
      "DYNAMICSRETRIEVALSESSIONID               \n",
      "UG1-001                               117\n",
      "UG1-002                                30\n",
      "UG1-003                                15\n"
     ]
    }
   ],
   "source": [
    "print('The Roadnet order lines were split by warehouse and route ID, into ' + str(number_of_sessionIDs) + ' files.  The lines were split as follows:')\n",
    "print(rdnet_in.groupby(['DYNAMICSRETRIEVALSESSIONID']).agg({'INVENTTRANSID': 'count'}))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_out['INVENTTRANSID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
