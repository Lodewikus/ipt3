{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script summary\n",
    "- Import many xml files that were generated by the Send to Roadnet process in D365\n",
    "- Perform processing on the XML files, and import them into a Pandas dataframe containing outbound order lines from D365\n",
    "- Convert this into a dataframe that emulates the data that Roadnet would have returned - apply spec for every field in the file\n",
    "- Import a list of SessionIDs, one for each user (or virtual user) that will be importing and posting an inbound file from Roadnet\n",
    "- Split the inbound file (from Roadnet) into one file per SessionID\n",
    "- Export as CSV (take note lines must end with CR-NL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filenames\n",
    "consolidated_roadnet_out_file = 'data/roadnet/xml_consolidated/consolidated_roadnet_out.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "except:\n",
    "    pass\n",
    "    #print(consolidated_roadnet_out_file + ' not in folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the xml_prep folder\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)\n",
    "\n",
    "# Clean up the xml_consolidated folder\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert D365 XML outbound files from a single line (with no newlines) to multiple lines by inserting a newline after evert '>' character\n",
    "- Store the resulting files in the /xml_prep/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 73 XML files in  data/roadnet/xml_outbound/\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_outbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(\"Loading \" + str(len(dir_list)) + \" XML files in \", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_multiple_lines(fname, fnum):\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        # reading line by line\n",
    "        lines = fr.readlines()\n",
    "        last_line = len(lines)\n",
    "        #print(last_line)\n",
    "\n",
    "    for line in lines:\n",
    "        replaced_line = re.sub(\">\", \">\\u000A\", line)\n",
    "\n",
    "    outfile = 'data/roadnet/xml_prep/f'+str(fnum)+'.xml'\n",
    "\n",
    "    with open(outfile, 'w') as fw:\n",
    "        fw.write(replaced_line)    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert xml from D365 by adding newlines\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    #print(xml_file)\n",
    "    xml_to_multiple_lines(xml_file,i)\n",
    "\n",
    "number_of_xml = len(dir_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate the processed XML outbound files into a single, consolidated xml file\n",
    "- Remove all lines that are not transaction line items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_prep/\"\n",
    "prep_dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_roadnet_files2(fname, fnum, outfile):\n",
    "\n",
    "    try:    \n",
    "        with open(fname, 'r') as fr:\n",
    "            # reading line by line\n",
    "            lines = fr.readlines()\n",
    "\n",
    "            last_line = len(lines)\n",
    "\n",
    "            # opening in writing mode\n",
    "            with open(outfile, 'a') as fw:\n",
    "                for line in lines:      \n",
    "                    substr1 = 'CCBROADNETWORKBENCHSESSIONTABLEENTITY'       \n",
    "                    x1 = re.search(substr1, line)\n",
    "                    substr2 = 'Document>'       \n",
    "                    x2 = re.search(substr2, line)\n",
    "                    substr3 = 'xml version='       \n",
    "                    x3 = re.search(substr3, line)\n",
    "                    #print(x)\n",
    "                    if x1 == None and x2 == None and x3 == None:\n",
    "                        fw.write(line)\n",
    "        #print(fname+\" lines deleted\")\n",
    "\n",
    "    except:\n",
    "        print(\"Error importing \"+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(prep_dir_list)):\n",
    "    xml_file = path+prep_dir_list[i]\n",
    "    #print(i)\n",
    "    #print(xml_file)\n",
    "    import_roadnet_files2(xml_file,i, consolidated_roadnet_out_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the consolidated xml file into 5,000 lines, else they cannot be imported into a Pandas dataframe\n",
    "- Store these files in the same folder as the consolidated xml, and delete the consolidated xml after the split\n",
    "- Add the lines to turn this into a valid XML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = consolidated_roadnet_out_file\n",
    "outfile = fname\n",
    "\n",
    "sizelimit = 5000\n",
    "\n",
    "try:    \n",
    "    with open(fname, 'r') as fr:\n",
    "        # reading line by line\n",
    "        lines = fr.readlines()\n",
    "\n",
    "        last_line = len(lines)\n",
    "\n",
    "        line_counter = 1\n",
    "\n",
    "        # opening in writing mode\n",
    "        last_x = 0\n",
    "        for i in range(0,len(lines)):\n",
    "            line = lines[i]\n",
    "            if i == last_line:\n",
    "                print(line)\n",
    "            x = int(i/sizelimit)\n",
    "            with open(outfile[:-4]+str(x)+'.xml', 'a') as fw:        \n",
    "                if i == 0:\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                if x > last_x:\n",
    "                    last_x = x\n",
    "                    fw.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                    fw.write('<Document>\\n')\n",
    "                fw.write(line)\n",
    "                if int((i+1)/sizelimit) > x:\n",
    "                    fw.write('</Document>')\n",
    "                if i == len(lines) - 1:\n",
    "                    fw.write('</Document>')\n",
    "    os.remove(consolidated_roadnet_out_file)\n",
    "                \n",
    "except:\n",
    "    print(\"Error importing \"+fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the transformed XML files into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files and directories\n",
    "path = \"data/roadnet/xml_consolidated/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "#print(\"Files and directories in '\", path, \"' :\")\n",
    "\n",
    "# prints all files\n",
    "#print(dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try1 = pd.read_xml(\"./data/roadnet/xml_consolidated/consolidated_roadnet_out0.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the first file into a dataframe\n",
    "rdnet_out = pd.read_xml(path+dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1data/roadnet/xml_consolidated/consolidated_roadnet_out5.xml\n",
      "2data/roadnet/xml_consolidated/consolidated_roadnet_out9.xml\n",
      "3data/roadnet/xml_consolidated/consolidated_roadnet_out3.xml\n",
      "4data/roadnet/xml_consolidated/consolidated_roadnet_out0.xml\n",
      "5data/roadnet/xml_consolidated/consolidated_roadnet_out1.xml\n",
      "6data/roadnet/xml_consolidated/consolidated_roadnet_out4.xml\n",
      "7data/roadnet/xml_consolidated/consolidated_roadnet_out6.xml\n",
      "8data/roadnet/xml_consolidated/consolidated_roadnet_out2.xml\n",
      "9data/roadnet/xml_consolidated/consolidated_roadnet_out7.xml\n",
      "10data/roadnet/xml_consolidated/consolidated_roadnet_out8.xml\n"
     ]
    }
   ],
   "source": [
    "# Import the rest of the files, and append to the dataframe\n",
    "for i in range(1,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    print(str(i)+xml_file)\n",
    "    temp = pd.read_xml(path+dir_list[i])\n",
    "    rdnet_out = pd.concat([rdnet_out, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52710"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INVENTTRANSID</th>\n",
       "      <th>BLOCKEDSTATUS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>CREDITRELEASEDATE</th>\n",
       "      <th>CREDITRELEASETIME</th>\n",
       "      <th>DAILYURGENCYINCREASE</th>\n",
       "      <th>DEPENDENCY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>DYNAMICSINTERNALSESSIONID</th>\n",
       "      <th>ERROR</th>\n",
       "      <th>...</th>\n",
       "      <th>REFTABLEID</th>\n",
       "      <th>ROADNETROUTE</th>\n",
       "      <th>SALESMANAGER</th>\n",
       "      <th>SHIPDATE</th>\n",
       "      <th>URGENCY</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>WAREHOUSEDESC</th>\n",
       "      <th>WAREHOUSEID</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>WEIGHTUNIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZA1-108660005</td>\n",
       "      <td>0</td>\n",
       "      <td>Polokwane</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pretoria Finished Goods WH</td>\n",
       "      <td>ZA1-000021129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4067</td>\n",
       "      <td>ZA014B00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.641714e+10</td>\n",
       "      <td>Pretoria Finished Goods WH</td>\n",
       "      <td>ZA014B</td>\n",
       "      <td>9388.8</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZA1-108660009</td>\n",
       "      <td>0</td>\n",
       "      <td>Polokwane</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pretoria Finished Goods WH</td>\n",
       "      <td>ZA1-000021129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4067</td>\n",
       "      <td>ZA014B00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.098124e+10</td>\n",
       "      <td>Pretoria Finished Goods WH</td>\n",
       "      <td>ZA014B</td>\n",
       "      <td>17702.4</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZA1-108660013</td>\n",
       "      <td>0</td>\n",
       "      <td>Polokwane</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pretoria Finished Goods WH</td>\n",
       "      <td>ZA1-000021129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4067</td>\n",
       "      <td>ZA014B00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Pretoria Finished Goods WH</td>\n",
       "      <td>ZA014B</td>\n",
       "      <td>9432.0</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZA1-101133446</td>\n",
       "      <td>0</td>\n",
       "      <td>Nongoma</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BROWNS NONGOMA</td>\n",
       "      <td>ZA1-000021135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>ZA032B03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.190988e+08</td>\n",
       "      <td>Phoenix Finished Goods WH</td>\n",
       "      <td>ZA032B</td>\n",
       "      <td>160.5</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZA1-101134190</td>\n",
       "      <td>0</td>\n",
       "      <td>Nongoma</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BROWNS NONGOMA</td>\n",
       "      <td>ZA1-000021135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>ZA032B03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-17T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.270080e+08</td>\n",
       "      <td>Phoenix Finished Goods WH</td>\n",
       "      <td>ZA032B</td>\n",
       "      <td>86.0</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52705</th>\n",
       "      <td>ZA1-109297498</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZA1-000021190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>ZA014B02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52706</th>\n",
       "      <td>ZA1-109297499</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZA1-000021190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>ZA014B02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52707</th>\n",
       "      <td>ZA1-109297500</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZA1-000021190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>ZA014B02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52708</th>\n",
       "      <td>ZA1-109297501</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZA1-000021190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>ZA014B02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52709</th>\n",
       "      <td>ZA1-109297528</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZA1-000021190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1328</td>\n",
       "      <td>ZA014B02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900-01-01T00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52671 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       INVENTTRANSID  BLOCKEDSTATUS       CITY          CREDITRELEASEDATE  \\\n",
       "0      ZA1-108660005              0  Polokwane  1900-01-01T00:00:00+00:00   \n",
       "1      ZA1-108660009              0  Polokwane  1900-01-01T00:00:00+00:00   \n",
       "2      ZA1-108660013              0  Polokwane  1900-01-01T00:00:00+00:00   \n",
       "3      ZA1-101133446              0    Nongoma  1900-01-01T00:00:00+00:00   \n",
       "4      ZA1-101134190              0    Nongoma  1900-01-01T00:00:00+00:00   \n",
       "...              ...            ...        ...                        ...   \n",
       "52705  ZA1-109297498              0        NaN  1900-01-01T00:00:00+00:00   \n",
       "52706  ZA1-109297499              0        NaN  1900-01-01T00:00:00+00:00   \n",
       "52707  ZA1-109297500              0        NaN  1900-01-01T00:00:00+00:00   \n",
       "52708  ZA1-109297501              0        NaN  1900-01-01T00:00:00+00:00   \n",
       "52709  ZA1-109297528              0        NaN  1900-01-01T00:00:00+00:00   \n",
       "\n",
       "       CREDITRELEASETIME  DAILYURGENCYINCREASE  DEPENDENCY  \\\n",
       "0                      0                     0           0   \n",
       "1                      0                     0           0   \n",
       "2                      0                     0           0   \n",
       "3                      0                     0           0   \n",
       "4                      0                     0           0   \n",
       "...                  ...                   ...         ...   \n",
       "52705                  0                     0           0   \n",
       "52706                  0                     0           0   \n",
       "52707                  0                     0           0   \n",
       "52708                  0                     0           0   \n",
       "52709                  0                     0           0   \n",
       "\n",
       "                      DESCRIPTION DYNAMICSINTERNALSESSIONID  ERROR  ...  \\\n",
       "0      Pretoria Finished Goods WH             ZA1-000021129    NaN  ...   \n",
       "1      Pretoria Finished Goods WH             ZA1-000021129    NaN  ...   \n",
       "2      Pretoria Finished Goods WH             ZA1-000021129    NaN  ...   \n",
       "3                  BROWNS NONGOMA             ZA1-000021135    NaN  ...   \n",
       "4                  BROWNS NONGOMA             ZA1-000021135    NaN  ...   \n",
       "...                           ...                       ...    ...  ...   \n",
       "52705                         NaN             ZA1-000021190    NaN  ...   \n",
       "52706                         NaN             ZA1-000021190    NaN  ...   \n",
       "52707                         NaN             ZA1-000021190    NaN  ...   \n",
       "52708                         NaN             ZA1-000021190    NaN  ...   \n",
       "52709                         NaN             ZA1-000021190    NaN  ...   \n",
       "\n",
       "      REFTABLEID ROADNETROUTE SALESMANAGER                   SHIPDATE  \\\n",
       "0           4067     ZA014B00          NaN  2023-08-17T00:00:00+00:00   \n",
       "1           4067     ZA014B00          NaN  2023-08-17T00:00:00+00:00   \n",
       "2           4067     ZA014B00          NaN  2023-08-17T00:00:00+00:00   \n",
       "3           1328     ZA032B03          NaN  2023-08-17T00:00:00+00:00   \n",
       "4           1328     ZA032B03          NaN  2023-08-17T00:00:00+00:00   \n",
       "...          ...          ...          ...                        ...   \n",
       "52705       1328     ZA014B02          NaN  1900-01-01T00:00:00+00:00   \n",
       "52706       1328     ZA014B02          NaN  1900-01-01T00:00:00+00:00   \n",
       "52707       1328     ZA014B02          NaN  1900-01-01T00:00:00+00:00   \n",
       "52708       1328     ZA014B02          NaN  1900-01-01T00:00:00+00:00   \n",
       "52709       1328     ZA014B02          NaN  1900-01-01T00:00:00+00:00   \n",
       "\n",
       "       URGENCY        VOLUME               WAREHOUSEDESC  WAREHOUSEID  \\\n",
       "0            0  1.641714e+10  Pretoria Finished Goods WH       ZA014B   \n",
       "1            0  3.098124e+10  Pretoria Finished Goods WH       ZA014B   \n",
       "2            0  0.000000e+00  Pretoria Finished Goods WH       ZA014B   \n",
       "3            0  3.190988e+08   Phoenix Finished Goods WH       ZA032B   \n",
       "4            0  1.270080e+08   Phoenix Finished Goods WH       ZA032B   \n",
       "...        ...           ...                         ...          ...   \n",
       "52705        0  0.000000e+00                         NaN          NaN   \n",
       "52706        0  0.000000e+00                         NaN          NaN   \n",
       "52707        0  0.000000e+00                         NaN          NaN   \n",
       "52708        0  0.000000e+00                         NaN          NaN   \n",
       "52709        0  0.000000e+00                         NaN          NaN   \n",
       "\n",
       "        WEIGHT WEIGHTUNIT  \n",
       "0       9388.8         CS  \n",
       "1      17702.4         CS  \n",
       "2       9432.0         CS  \n",
       "3        160.5         CS  \n",
       "4         86.0         CS  \n",
       "...        ...        ...  \n",
       "52705      0.0         KG  \n",
       "52706      0.0         KG  \n",
       "52707      0.0         KG  \n",
       "52708      0.0         KG  \n",
       "52709      0.0         KG  \n",
       "\n",
       "[52671 rows x 40 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdnet_out[rdnet_out.duplicated(['INVENTTRANSID'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_out.drop(columns={'OUTPERFORMROADNETDESTINATION'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_out.query(\"INVENTTRANSID == 'ZA1-108660005'\").to_excel(\"./data/roadnet/duplicates.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_out = rdnet_out.drop_duplicates(keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4663"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_out = rdnet_out.drop_duplicates(subset = ['INVENTTRANSID'], keep='first').copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Roadnet inbound file by copying selected columns as-is from the outbound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_out[['QUANTITY','LOCATIONID','INVENTTRANSID','ITEMID','ORDERID','WAREHOUSEID','PRODUCTNAME','ROADNETROUTE','ORDERACCOUNT','ORDERACCOUNTNAME','WEIGHT']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = rdnet_in.dropna(subset=['WAREHOUSEID']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_in[rdnet_in. duplicated(subset = ['INVENTTRANSID'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_in[rdnet_in. duplicated(subset = ['INVENTTRANSID'], keep=False)].to_excel(\"./data/roadnet/rdnet_in_dup.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'QUANTITY':'CASEQTY','LOCATIONID':'DESTINATIONLOCATIONID','ORDERID':'ORDERNUMBER','WAREHOUSEID':'ORIGINLOCATIONID','ORDERACCOUNT':'STOPLOCATIONID','ORDERACCOUNTNAME':'STOPLOCATIONNAME'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the rest of the fields as per the Roadnet inbound file spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.now())\n",
    "today = today.replace(':','h')\n",
    "today = today.replace('-','')\n",
    "today = today.replace(' ','-')\n",
    "today = today[0:14] + '-'\n",
    "#print(\"Today date is: \", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROADNETROUTEINTERNALROUTEID'] = today + rdnet_in['STOPLOCATIONID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_customers = len(rdnet_in['STOPLOCATIONID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['APPTID'] = ''\n",
    "rdnet_in['DESCRIPTION'] = 'BLOEM_PLAN'\n",
    "rdnet_in['ERROR'] = ''\n",
    "rdnet_in['FIRSTDRIVER'] = '825196'\n",
    "rdnet_in['FIRSTTRAILER'] = 'ST29PTAIL'\n",
    "rdnet_in['LASTSTOPISDESTINATION'] = 'No'\n",
    "rdnet_in['LOADID'] = ''\n",
    "rdnet_in['LOADTEMPLATEID'] = ''\n",
    "rdnet_in['ORDERTYPE'] = 'rotOrder'\n",
    "rdnet_in['ORIGINDESTINATION'] = 'Yes'\n",
    "rdnet_in['PALLETQTY'] = '0'\n",
    "rdnet_in['REFERENCECATEGORY'] = 'Sales'\n",
    "rdnet_in['REFERENCEDOCUMENT'] = 'SalesOrder'\n",
    "rdnet_in['ROADNETINTERNALSESSIONID'] = '35411'\n",
    "rdnet_in['ROADNETREGIONID'] = 'ZA1'\n",
    "rdnet_in['ROUTECODE'] = ''\n",
    "rdnet_in['SECONDDRIVER'] = ''\n",
    "rdnet_in['SECONDTRAILER'] = ''\n",
    "rdnet_in['SEQUENCEDISTANCE'] = '.000000'\n",
    "rdnet_in['SEQUENCENUMBER'] = '1'\n",
    "rdnet_in['SEQUENCETRAVELTIME'] = '0'\n",
    "rdnet_in['SHIPPINGCARRIER'] = '0'\n",
    "rdnet_in['STATUS'] = 'Error'\n",
    "rdnet_in['STOPTYPE'] = 'stpStop'\n",
    "rdnet_in['TOTALDISTANCE'] = '.000000'\n",
    "rdnet_in['TOTALROUTEDISTANCE'] = '.000000'\n",
    "rdnet_in['TRUCKANDTRAILERASSIGNED'] = 'No'\n",
    "rdnet_in['UNITID'] = ''\n",
    "rdnet_in['VEHICLEID'] = 'TT4X2TAIL'\n",
    "rdnet_in['STOPSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALSERVICETIME'] = '720'\n",
    "rdnet_in['TOTALTRAVELTIME'] = '0'\n",
    "rdnet_in['LINEREFID'] = rdnet_in['INVENTTRANSID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_txt = input('Enter the dispatch date in the format yyyy-mm-dd: ')\n",
    "date_dt = pd.to_datetime(date_txt)\n",
    "#date_dt = pd.to_datetime('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['ROUTECOMPLETETIME'] = date_dt\n",
    "rdnet_in['ROUTECOMPLETETIME'] = rdnet_in['ROUTECOMPLETETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=13) + pd.Timedelta(minutes=19)\n",
    "\n",
    "rdnet_in['ROUTESTARTTIME'] = date_dt\n",
    "rdnet_in['ROUTESTARTTIME'] = rdnet_in['ROUTESTARTTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDARRIVALDATETIME'] = rdnet_in['SCHEDULEDARRIVALDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=12) + pd.Timedelta(minutes=59)\n",
    "\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDDELIVERYDATETIME'] = rdnet_in['SCHEDULEDDELIVERYDATETIME'].dt.normalize() + pd.Timedelta(days=0)\n",
    "\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = date_dt\n",
    "rdnet_in['SCHEDULEDSHIPDATETIME'] = rdnet_in['SCHEDULEDSHIPDATETIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=4) + pd.Timedelta(minutes=10)\n",
    "\n",
    "rdnet_in['STOPARRIVALTIME'] = date_dt\n",
    "rdnet_in['STOPARRIVALTIME'] = rdnet_in['STOPARRIVALTIME'].dt.normalize() + pd.Timedelta(days=0) + pd.Timedelta(hours=8) + pd.Timedelta(minutes=28)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get customer master in order to get the postal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the customer master to obtain the zipcode\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the customer master to obtain the zipcode\")\n",
    "#Do the following once-off to create the parquet file\n",
    "#customers=pd.read_csv(\"./data/customers/2023-08-10_CustomersV3.csv\",low_memory=False)\n",
    "#customers.to_parquet(\"./data/customers.parquet\")\n",
    "customers=pd.read_parquet(\"./data/customers.parquet\")\n",
    "customers_short = customers[['ADDRESSZIPCODE','CUSTOMERACCOUNT','ORGANIZATIONNAME']].copy()\n",
    "#customers_short=pd.read_csv(\"./data/customers/customers_short.csv\",low_memory=False)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].fillna(0)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(int)\n",
    "customers_short['ADDRESSZIPCODE'] = customers_short['ADDRESSZIPCODE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3983"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in_bk=rdnet_in.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To restore\n",
    "#rdnet_in=rdnet_in_bk.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    customers_short,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='STOPLOCATIONID',\n",
    "    right_on='CUSTOMERACCOUNT',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.rename(columns={'ADDRESSZIPCODE':'STOPPOSTALCODE'}, inplace=True)\n",
    "rdnet_in.drop(columns={'CUSTOMERACCOUNT', 'ORGANIZATIONNAME'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_in['STOPPOSTALCODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdnet_in.sort_values(['ORIGINLOCATIONID','ROADNETROUTE']).to_csv('data/roadnet/try1.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split file into n files, each with a different ORIGINLOCATIONID\n",
    "- Read csv file with ORIGINLOCATIONIDs\n",
    "- Generate a dataframe with the unique list of warehouses\n",
    "- Add a column (Group) to that dataframe where the warehouses are assigned into n groups\n",
    "- Generate n output files, each with ORIGINLOCATIONID as from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input('Remember to update data/roadnet/sessionIDs.csv with the list of session IDs.  This will determine how the Roadnet inbound file will be split.  Press \"Enter\" to continue. ')\n",
    "sessionids = pd.read_csv('data/roadnet/sessionIDs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting inbound files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting inbound files per sessionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionids_list = sessionids.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_warehouses_np = rdnet_in['ORIGINLOCATIONID'].unique()\n",
    "unique_warehouses_df = pd.DataFrame(unique_warehouses_np)\n",
    "number_of_warehouses = len(rdnet_in['ORIGINLOCATIONID'].unique())\n",
    "number_of_sessionIDs = len(sessionids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_warehouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if number_of_warehouses < number_of_sessionIDs:\n",
    "    raise SystemExit(\"There are more sessionIDs than warehouses - some of the output files will have no lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in['WH_route_combination'] = rdnet_in['ORIGINLOCATIONID'].astype(str) + rdnet_in['ROADNETROUTE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code to do a more equal distrobution of warehouses (itv of lines) over the sessions. \n",
    "# If there are 8 sessionIDs (i.e. virtual users), do it the following way:\n",
    "# Step through warehouses from one with most lines to one with fewest lines\n",
    "# Assign sequentially to the users 1 to 8\n",
    "# Then, assign the remaining in reverse order from 8 to 1, continue allocating in descending quantity. Wrap back to 8 if needed.\n",
    "\n",
    "#x = rdnet_in.groupby(['ORIGINLOCATIONID','ROADNETROUTE']).agg({'INVENTTRANSID': 'count', 'WH_route_combination': 'first'}).sort_values('INVENTTRANSID',ascending=False).reset_index().copy()\n",
    "x = rdnet_in.groupby(['WH_route_combination']).agg({'INVENTTRANSID': 'count'}).sort_values('INVENTTRANSID',ascending=False).reset_index().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['sessionID'] = ''\n",
    "user = 0\n",
    "user_ascending = True\n",
    "for i in range(len(x)):\n",
    "    if user_ascending == True and user < number_of_sessionIDs:\n",
    "        user = user + 1\n",
    "\n",
    "    if user_ascending == False and user <= number_of_sessionIDs:\n",
    "        if user > 1:\n",
    "            user = user - 1\n",
    "        else:\n",
    "            user = number_of_sessionIDs\n",
    "\n",
    "    if user_ascending == True and user == number_of_sessionIDs:\n",
    "        user_ascending = False\n",
    "        user = number_of_sessionIDs           \n",
    "\n",
    "    x.at[i, 'sessionID'] = str(sessionids_list[user-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(columns={'INVENTTRANSID'}, inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge back the warehouse-based split into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3240"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in = pd.merge(\n",
    "    rdnet_in,\n",
    "    x,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='WH_route_combination',\n",
    "    right_on='WH_route_combination',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3240"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdnet_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdnet_in.drop(columns={'WH_route_combination'}, inplace=True, axis=1)\n",
    "rdnet_in.rename(columns={'sessionID':'DYNAMICSRETRIEVALSESSIONID'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV files per sessionID\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing CSV files per sessionID\")\n",
    "# Clean up the folder where the inbound files are to be stored\n",
    "path = \"data/roadnet/inbound/\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "for i in range(0,len(dir_list)):\n",
    "    xml_file = path+dir_list[i]\n",
    "    os.remove(xml_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sessionID in sessionids_list:\n",
    "    mask = (rdnet_in['DYNAMICSRETRIEVALSESSIONID'] == sessionID[0])\n",
    "    df_temp = rdnet_in[mask].copy()\n",
    "    filename = 'data/roadnet/inbound/rdnet_inbound_'+sessionID[0]\n",
    "    df_temp.to_csv(filename+'.csv',index=False, lineterminator='\\r\\n')    \n",
    "    df_temp.to_xml(filename+'.xml',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Roadnet order lines were split by warehouse and route ID, into 5 files.  The lines were split as follows:\n",
      "                            INVENTTRANSID\n",
      "DYNAMICSRETRIEVALSESSIONID               \n",
      "ZA1-000007781                         697\n",
      "ZA1-000007782                         745\n",
      "ZA1-000007783                         645\n",
      "ZA1-000007784                         677\n",
      "ZA1-000007785                         476\n"
     ]
    }
   ],
   "source": [
    "print('The Roadnet order lines were split by warehouse and route ID, into ' + str(number_of_sessionIDs) + ' files.  The lines were split as follows:')\n",
    "print(rdnet_in.groupby(['DYNAMICSRETRIEVALSESSIONID']).agg({'INVENTTRANSID': 'count'}))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
