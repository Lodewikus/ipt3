{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime, date, time\n",
    "#import pyodbc\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_extract = pd.read_csv(\"./data/execution/CC_export__executionsteplog__202309201735.csv\", low_memory=False)\n",
    "#sql_extract = pd.read_csv(\"./data/execution/_SELECT_ExecutionLog_scriptname_ExecutionStepLog_id_ExecutionSte_202309260930.csv\", low_memory=False)\n",
    "sql_extract = pd.read_csv(\"./data/execution/_SELECT_ExecutionLog_scriptname_ExecutionStepLog_id_ExecutionSte_202309281612.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_extract.rename(columns={'linenum': 'lineNum', 'executionid': 'executionLogsId', 'scriptname': 'scriptName', 'label': 'label', 'status': 'step_status', 'starttime': 'startTime', 'endtime': 'endTime', 'duration': 'duration', 'id': 'StepLogsId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4188860 entries, 0 to 4188859\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   scriptName       object \n",
      " 1   StepLogsId       int64  \n",
      " 2   executionLogsId  int64  \n",
      " 3   lineNum          int64  \n",
      " 4   labelkey         object \n",
      " 5   label            object \n",
      " 6   labelparams      object \n",
      " 7   startTime        object \n",
      " 8   endTime          object \n",
      " 9   duration         float64\n",
      " 10  step_status      object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 351.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sql_extract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_extract.head(1000).to_csv(\"./data/execution/SQL_head.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Initial extraction completed",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Initial extraction completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wikus/code/ipt3/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "raise SystemExit(\"Initial extraction completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get EA script history in JSON format via the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_date = '2023-09-18'\n",
    "extract_start = '2023-08-01T00:00:00.000Z'\n",
    "extract_finish = '2023-09-20T23:59:00.000Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET /api/bi/scripts?filter[where][createdAt][between][0]=2023-07-09T22:00:00.523Z&filter[where][createdAt][between][1]=2023-09-07T21:59:59.523Z&withHistory=true\n",
    "url = 'https://ea.executive.automats.app/api/bi/scripts?filter[where][createdAt][between][0]=' + extract_start + 'filter[where][createdAt][between][1]=' + extract_finish + '&withHistory=true'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wikus/code/ipt3/env/lib/python3.10/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ea.executive.automats.app'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "custom_headers  = {\"Authorization\": \"aeG09Z8IE54TNw759z6Eg2SAC432WIJ2S4uChfCTXse7xnaUNVmo0vBuoPLYB0o3\", \"Content-Type\": \"application/json\"}\n",
    "#url = 'https://ea.executive.automats.app/api/bi/scripts?withHistory=true'\n",
    "\n",
    "url = 'https://ea.executive.automats.app/api/bi/scripts?filter[where][createdAt][between][0]=' + extract_start + '&filter[where][createdAt][between][1]=' + extract_finish + '&withHistory=true'\n",
    "#url = 'https://ea.executive.automats.app/api/bi/scripts?filter[where][startTime][between][0]=' + extract_start + '&filter[where][startTime][between][1]=' + extract_finish + '&withHistory=true'\n",
    "\n",
    "\n",
    "resp = requests.get(url, headers = custom_headers, verify=False)\n",
    "print(resp.status_code)\n",
    "\n",
    "# Previous runtime = 2min 55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(resp.text)\n",
    "json_text = json.dumps(json_data, indent=4)\n",
    "\n",
    "# Previous runtime = 2min 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('data/execution/try.json')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "\n",
    "with open('data/execution/try.json', 'w') as fw:\n",
    "    fw.write(json_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove invalid characters from the inbound JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7403202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7403202/7403202 [02:36<00:00, 47258.77it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove('data/execution/script_history_fixed.json')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "\n",
    "#with open('data/execution/script_history.json', 'r') as fr:\n",
    "with open('data/execution/try.json', 'r') as fr:    \n",
    "    # reading line by line\n",
    "    lines = fr.readlines()\n",
    "    last_line = len(lines)\n",
    "    print(len(lines))\n",
    "    \n",
    "    for line in tqdm(lines):\n",
    "        line = re.sub(\"\\u0003\", \"\", line)\n",
    "        with open('data/execution/script_history_fixed.json', 'a') as fw:\n",
    "            fw.write(line) \n",
    "\n",
    "# Previous runtime = 5m 28s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the multilevel JSON into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/execution/script_history_fixed.json')\n",
    "data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/390 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:02<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove('data/execution/check_structure.csv')\n",
    "except:\n",
    "    print('File does not exist')\n",
    "with open('data/execution/check_structure.csv', 'a') as fw:\n",
    "    #line = 'topProjectName,name,sessionId,executionLogsId,scriptId,scriptName,script_status,label,step_state,step_status,startTime,endTime,duration,lineNum,StepLogsId,lastIssues\\n'\n",
    "    line = 'topProjectName,name,sessionId,executionLogsId,scriptId,scriptName,script_status,label,step_state,step_status,startTime,endTime,duration,lineNum,StepLogsId\\n'\n",
    "    fw.write(line)\n",
    "    i = 0\n",
    "    for level1 in tqdm(data):\n",
    "        # for key, value in level1.items():\n",
    "        #     #if i == 100: break\n",
    "        \n",
    "                     \n",
    "        try:\n",
    "            executionLogs_str = json.dumps(level1['executionLogs'])\n",
    "            executionLogs_json = json.loads(executionLogs_str)\n",
    "            for level2 in executionLogs_json:\n",
    "                for key2, value2 in level2.items():\n",
    "                    #try:\n",
    "                    startTime_str = str(level2['startTime'])\n",
    "                    startTime_str = startTime_str[0:10]\n",
    "                    startTime = datetime.strptime(startTime_str, '%Y-%m-%d')\n",
    "                    oldestHistory = datetime.strptime(run_date, '%Y-%m-%d')\n",
    "                    executionStepLogs_str = json.dumps(level2['executionStepLogs'])\n",
    "                    executionStepLogs_json = json.loads(executionStepLogs_str)\n",
    "                    if key2 == 'executionStepLogs' and startTime >= oldestHistory:\n",
    "                    #if key2 == 'executionStepLogs':\n",
    "\n",
    "                        topProjectName = str(level1['topProjectName'])\n",
    "                        name_str = str(level1['name'])\n",
    "                        # Remove any commas from name \n",
    "                        check = (',' in name_str)\n",
    "                        if check == True:\n",
    "                            name_str = re.sub(',', ';', name_str)                            \n",
    "                        sessionId_str = str(level2['sessionId'])\n",
    "                        id_str = str(level2['id'])\n",
    "                        scriptId_str = str(level2['scriptId'])\n",
    "                        scriptName_str = str(level2['scriptName'])\n",
    "                        # Remove any commas from scriptName \n",
    "                        check = (',' in scriptName_str)\n",
    "                        if check == True:\n",
    "                            scriptName_str = re.sub(',', ';', scriptName_str)                             \n",
    "                        state_str = str(level2['state'])\n",
    "                        status2_str = str(level2['status'])\n",
    "                        # lastIssues_str = str(level2['lastIssues'])\n",
    "                        # Remove any commas from lastIssues_str\n",
    "                        # check = (',' in lastIssues_str)\n",
    "                        # if check == True:\n",
    "                        #     lastIssues_str = re.sub(',', '~', lastIssues_str)\n",
    "                        # check = ('\\n' in lastIssues_str)\n",
    "                        # if check == True:\n",
    "                        #     lastIssues_str = re.sub('\\n', '|', lastIssues_str)                         \n",
    "\n",
    "\n",
    "                        for level3 in executionStepLogs_json:\n",
    "                            \n",
    "                            #for key3, value3 in level3.items():\n",
    "                            status3_str = str(level3['status'])\n",
    "                            label_str = str(level3['label'])\n",
    "                            \n",
    "                            # These lines replace long text test step labels with short text (that does not wrap)\n",
    "                            check = ('Click Dynamics 365' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Click Dynamics 365'\n",
    "                            check = ('Click Sales Hub' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Click Sales Hub'\n",
    "                            check = ('Type value function eaExecuteVariableValue()' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Type value function eaExecuteVariableValue()'\n",
    "                            check = ('Select from function eaExecuteVariableValue()' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Select from function eaExecuteVariableValue()'                                    \n",
    "                            check = ('Select lookup values function eaExecuteVariableValue()' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = 'Select lookup values function eaExecuteVariableValue()'\n",
    "                            # Remove any commas from label_str \n",
    "                            check = (',' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = re.sub(',', ';', label_str)\n",
    "                            # Now replace all newlines that remain in label_str\n",
    "                            check = ('\\n' in label_str)\n",
    "                            if check == True:\n",
    "                                label_str = re.sub('\\n', '/nl/', label_str)\n",
    "                            # Done with replacing text\n",
    "\n",
    "                            startTime_str = str(level3['startTime'])\n",
    "                            endTime_str = str(level3['endTime'])\n",
    "                            duration_str = str(level3['duration'])\n",
    "                            lineNum_str = str(level3['lineNum'])\n",
    "                            StepLogs_id_str = str(level3['id'])\n",
    "\n",
    "                            i = i + 1\n",
    "\n",
    "                            #line = topProjectName+','+name_str+','+sessionId_str+','+id_str+','+scriptId_str+','+scriptName_str+','+status2_str+','+label_str+','+state_str+','+status3_str+','+startTime_str+','+endTime_str+','+duration_str+','+lineNum_str+','+StepLogs_id_str+','+lastIssues_str+'\\n'\n",
    "                            line = topProjectName+','+name_str+','+sessionId_str+','+id_str+','+scriptId_str+','+scriptName_str+','+status2_str+','+label_str+','+state_str+','+status3_str+','+startTime_str+','+endTime_str+','+duration_str+','+lineNum_str+','+StepLogs_id_str+'\\n'\n",
    "                            fw.write(line)\n",
    "                            if level3['id'] == 2:\n",
    "                                print(line)                                \n",
    "                        # except:\n",
    "                        #     print('Exception on Level2 for Level1 item '+str(i))\n",
    "        except:\n",
    "            #print('Exception for Level1 item '+str(i))\n",
    "            pass       \n",
    "\n",
    "    # Previous runtime = 2min 40s   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the denormalized CSV file into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/execution/check_structure.csv')\n",
    "\n",
    "# Previous runtime = 2.2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run from here again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundate = '2023-09-28'\n",
    "df = sql_extract.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'label':'StepLabel'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['scriptName']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.dropna(subset=['startTime']).copy()\n",
    "df = df.dropna(subset=['endTime']).copy()\n",
    "df = df.sort_values(by=['startTime'], ascending=False).copy()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['duration'] == 'None') \n",
    "df['duration'].mask(mask,'0',inplace=True)\n",
    "df['duration'] = pd.to_numeric(df['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_sec'] = df.duration/1000\n",
    "df['duration_mins'] = df.duration/1000/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['date'] = pd.to_datetime(df['startTime'], format='%Y-%m-%d', utc=True).dt.date\n",
    "df['date'] = pd.to_datetime(df['startTime'], format='mixed', utc=True).dt.date\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"date == @rundate\").copy()  # Remember time is UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['startTime'], utc=True).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_dec'] = df['time'].astype(str)\n",
    "df['time_dec'] = df['time_dec'].str[:5]\n",
    "df['time_dec'] = df['time_dec'].str.replace(':','.')\n",
    "df['time_dec'] = df['time_dec'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a column to indicate Runs of each test script\n",
    "As there is no other field available via the API, this field is generated each time the lineNum == 1.  This assumes that there will always be a step 1 in every test case.\n",
    "Before this can be done, first sort the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['executionLogsId','StepLogsId'], inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the new code to allocate a 'run' number and increment it every time the lineNum == 1.  This was generated by ChatGPT based on the code above :-)\n",
    "\n",
    "df['run'] = (df['lineNum'] == 1).cumsum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a field to indicate where test scripts have run to the last step of the script\n",
    "This assumes that the last step is \"End script\"\n",
    "First sort the dataframe by Runs\n",
    "Then add a new text field that is a concatenation of all the step labels for each run\n",
    "Finally, check which of those strings contain the text \"End script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_np = df.run.unique()\n",
    "end_script_dict = {}\n",
    "for i in runs_np:\n",
    "    end_script_dict[i] = 'Script stopped'\n",
    "step_error_dict = {}\n",
    "for i in runs_np:\n",
    "    step_error_dict[i] = 'No step errors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['run'], inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df.index:\n",
    "    #if run == 10: break\n",
    "    run = df['run'][idx]\n",
    "    if df['StepLabel'][idx] == 'End script':\n",
    "        end_script_dict[run] = 'Script completed'\n",
    "    if df['step_status'][idx] == 'ERROR':\n",
    "        step_error_dict[run] = 'One or more step errors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_script_df = pd.DataFrame.from_dict(end_script_dict,orient ='index',columns=['script_completion'])\n",
    "end_script_df.reset_index(inplace=True)\n",
    "end_script_df.rename(columns={'index':'run'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_error_df = pd.DataFrame.from_dict(step_error_dict,orient ='index',columns=['step_error'])\n",
    "step_error_df.reset_index(inplace=True)\n",
    "step_error_df.rename(columns={'index':'run'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df,\n",
    "    end_script_df,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='run',\n",
    "    right_on='run',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df,\n",
    "    step_error_df,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='run',\n",
    "    right_on='run',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'script_status': 'EA_script_status','step_state': 'EA_step_state','step_status': 'EA_step_status','step_error': 'IPT_step_error','script_completion': 'IPT_script_completion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94971 entries, 0 to 94970\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   scriptName             94971 non-null  object        \n",
      " 1   StepLogsId             94971 non-null  int64         \n",
      " 2   executionLogsId        94971 non-null  int64         \n",
      " 3   lineNum                94971 non-null  int64         \n",
      " 4   labelkey               23278 non-null  object        \n",
      " 5   StepLabel              73489 non-null  object        \n",
      " 6   labelparams            94971 non-null  object        \n",
      " 7   startTime              94971 non-null  object        \n",
      " 8   endTime                94971 non-null  object        \n",
      " 9   duration               94971 non-null  float64       \n",
      " 10  EA_step_status         94971 non-null  object        \n",
      " 11  duration_sec           94971 non-null  float64       \n",
      " 12  duration_mins          94971 non-null  float64       \n",
      " 13  date                   94971 non-null  datetime64[ns]\n",
      " 14  time                   94971 non-null  object        \n",
      " 15  time_dec               94971 non-null  float64       \n",
      " 16  run                    94971 non-null  int64         \n",
      " 17  IPT_script_completion  94971 non-null  object        \n",
      " 18  IPT_step_error         94971 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(4), object(10)\n",
      "memory usage: 13.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KPI'] = 'Not mapped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K1\n",
    "mask = (df['scriptName'].str.contains('Place a sales local order',case=False))\n",
    "df['KPI'].mask(mask,'K01 Place a sales local order',inplace=True)\n",
    "\n",
    "# K2\n",
    "mask = (df['scriptName'].str.contains('Place a B2B local order',case=False))\n",
    "df['KPI'].mask(mask,'K02 Place a B2B/EDI order and Send Confirmation',inplace=True)\n",
    "\n",
    "# K3 Place Service Portal Order\n",
    "# No test script\n",
    "\n",
    "# K4\n",
    "mask = (df['scriptName'].str.contains('Amend an existing sales order',case=False))\n",
    "df['KPI'].mask(mask,'K04 Amend an existing sales order',inplace=True)\n",
    "\n",
    "# K5\n",
    "mask = (df['scriptName'].str.contains('Trade Returns Order',case=False))\n",
    "df['KPI'].mask(mask,'K05 Place a Trade Returns Order',inplace=True)\n",
    "\n",
    "# K6\n",
    "mask = (df['scriptName'].str.contains('Submit a B2B Remittance',case=False))\n",
    "df['KPI'].mask(mask,'K06 B2B Remittance',inplace=True)\n",
    "\n",
    "# K7 B2B Remittance Adjustment\n",
    "# No test script\n",
    "\n",
    "#K8\n",
    "mask = (df['scriptName'].str.contains('Receipted payment processing',case=False))\n",
    "df['KPI'].mask(mask,'K08 Receipted payment processing SA Only at the moment',inplace=True)\n",
    "\n",
    "# K9 aDSD Batch Job posting invoice for HHD billing document \n",
    "# No test script\n",
    "\n",
    "# K10\n",
    "mask = (df['scriptName'].str.contains('Credit status check',case=False))\n",
    "df['KPI'].mask(mask,'K10 Credit status check',inplace=True)\n",
    "\n",
    "# K11\n",
    "mask = (df['scriptName'].str.contains('Send Load to Roadnet',case=False))\n",
    "df['KPI'].mask(mask,'K11 Send Load to Roadnet load for Planning',inplace=True)\n",
    "\n",
    "# K12\n",
    "mask = (df['scriptName'].str.contains('Receive load from Roadnet',case=False))\n",
    "df['KPI'].mask(mask,'K12 Receive load from Roadnet into D365',inplace=True)\n",
    "\n",
    "# K13b\n",
    "mask = (df['scriptName'].str.contains('Release to warehouse',case=False) & df['scriptName'].str.contains('Roadnet loads',case=False))\n",
    "df['KPI'].mask(mask,'K13b Release to Warehouse & Complete Picking Work (Roadnet loads)',inplace=True)\n",
    "# Release to Warehouse (Roadnet loads) & Complete Picking Work & Process OOS\n",
    "\n",
    "# K13\n",
    "mask = (df['scriptName'].str.contains('Release to Warehouse',case=False) & df['scriptName'].str.contains('manual',case=False))\n",
    "df['KPI'].mask(mask,'K13 Release to Warehouse (manually planned loads)',inplace=True)\n",
    "\n",
    "# K14 Complete Picking Work & Process OOS \n",
    "# Not mapped??\n",
    "\n",
    "\n",
    "# K14b\n",
    "mask = (df['scriptName'].str.contains('Complete Picking Work',case=False) & df['scriptName'].str.contains('manual loads',case=False))\n",
    "df['KPI'].mask(mask,'K14b Complete Picking Work & Process OOS (manually planned loads)',inplace=True)\n",
    "\n",
    "# K15\n",
    "mask = (df['scriptName'].str.contains('aDSD Load confirmation',case=False))\n",
    "df['KPI'].mask(mask,'K15 aDSD Load confirmation',inplace=True)\n",
    "\n",
    "# K16\n",
    "mask = (df['scriptName'].str.contains('Load upload',case=False) & df['scriptName'].str.contains('Settlement',case=False))\n",
    "df['KPI'].mask(mask,'K16 Load upload & Settlement',inplace=True)\n",
    "\n",
    "# K17\n",
    "mask = (df['scriptName'].str.contains('Create a cost estimate',case=False))\n",
    "df['KPI'].mask(mask,'K17 Create a cost estimate for all standard costed procured materials',inplace=True)\n",
    "\n",
    "# K18\n",
    "mask = (df['scriptName'].str.contains('Imported Statistical',case=False))\n",
    "df['KPI'].mask(mask,'K18 Import Actual Statistical entries, into Cost Accounting',inplace=True)\n",
    "\n",
    "# K19\n",
    "mask = (df['scriptName'].str.contains('Distribute the range of items pending prices',case=False))\n",
    "df['KPI'].mask(mask,'K19 Distribute the range of items pending prices to another site',inplace=True)\n",
    "\n",
    "# K20\n",
    "mask = ((df['scriptName'].str.contains('Cost Rollup',case=False) & df['scriptName'].str.contains('Cost Allocation',case=False)) | df['scriptName'].str.contains('Maintain cost distribution table',case=False))\n",
    "df['KPI'].mask(mask,'K20 Run Cost Rollup and Cost Allocation Policies',inplace=True)\n",
    "\n",
    "# K21\n",
    "mask = (df['scriptName'].str.contains('Place SFA order',case=False))\n",
    "df['KPI'].mask(mask,'K21 Place SFA order and Send Confirmation',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['KPI', 'scriptName', 'executionLogsId', 'run', 'lineNum'], inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['StepLabel']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Initial extraction completed",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Initial extraction completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wikus/code/ipt3/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "raise SystemExit(\"Initial extraction completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the dataset for output on a specific test cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_scripts = ['TEST TIMINGS','Test - 10 sessions', 'Gary Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.query(\"date == @rundate and time_dec > 10.0 and scriptName not in @exclude_scripts\").copy()  # Remember time is UTC\n",
    "#df1 = df.query(\"date == @rundate and time_dec > 10.0 and scriptName not in @exclude_scripts\").copy()  # Remember time is UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_runs = df1[df1['IPT_script_completion'] == 'Script completed'].groupby('KPI').agg({'run': 'nunique'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_runs = df1[df1['IPT_script_completion'] != 'Script completed'].groupby('KPI').agg({'run': 'nunique'}).reset_index()\n",
    "incomplete_runs.rename(columns={'run': 'Incomplete Runs', 'KPI': 'KPI Process'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark those Test Script Steps that must be included in the time measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['KPI_no'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Include_in_measure'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_numbers = ['K11', 'K12', 'K13', 'K14', 'K15', 'K16', 'K17', 'K18', 'K19', 'K20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73489/73489 [00:00<00:00, 234321.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(df1.index):\n",
    "    label = df1['StepLabel'][idx]\n",
    "    prefix = label[0:3]\n",
    "    if prefix in kpi_numbers:\n",
    "        if label[3] == 'b':\n",
    "            df1.at[idx, 'KPI_no'] = prefix + 'b'\n",
    "        else:\n",
    "            df1.at[idx, 'KPI_no'] = prefix  \n",
    "        df1.at[idx, 'Include_in_measure'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/execution/' + rundate +  '_results_filtered.csv'\n",
    "df1.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df1.query(\"Include_in_measure == True and EA_step_status != 'WARNING' and EA_step_status != 'ERROR'\").copy()\n",
    "df2 = df1.query(\"Include_in_measure == True and EA_step_status != 'ERROR'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates(keep='first')\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90th Percentile\n",
    "def q90(x):\n",
    "    return x.quantile(0.9)\n",
    "\n",
    "\n",
    "kpi_results = df2.groupby(['KPI_no']).agg({'KPI': 'first', 'duration_sec': ['mean', 'max', q90, 'std'], 'run': 'count'}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns\n",
    "kpi_results.columns = ['_'.join(col) for col in kpi_results.columns]\n",
    "kpi_results = kpi_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_results.rename(columns={'KPI_no_': 'KPI_no', 'KPI_first':'KPI Process', 'duration_sec_mean': 'Average', 'duration_sec_max': 'Max', 'duration_sec_q90': '90th_%', 'duration_sec_std': 'SD', 'run_count': 'Successful Runs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_results = pd.merge(\n",
    "    kpi_results,\n",
    "    incomplete_runs,\n",
    "    how=\"left\",\n",
    "    on=None,\n",
    "    left_on='KPI Process',\n",
    "    right_on='KPI Process',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "\n",
    "kpi_results['Incomplete Runs'] = kpi_results['Incomplete Runs'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_results = kpi_results.round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KPI_no</th>\n",
       "      <th>KPI Process</th>\n",
       "      <th>Average</th>\n",
       "      <th>Max</th>\n",
       "      <th>90th_%</th>\n",
       "      <th>SD</th>\n",
       "      <th>Successful Runs</th>\n",
       "      <th>Incomplete Runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K11</td>\n",
       "      <td>K11 Send Load to Roadnet load for Planning</td>\n",
       "      <td>3.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>91</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K12</td>\n",
       "      <td>K12 Receive load from Roadnet into D365</td>\n",
       "      <td>57.7</td>\n",
       "      <td>74.1</td>\n",
       "      <td>71.1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K13</td>\n",
       "      <td>K13 Release to Warehouse (manually planned loads)</td>\n",
       "      <td>27.3</td>\n",
       "      <td>81.4</td>\n",
       "      <td>48.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K14</td>\n",
       "      <td>K13 Release to Warehouse (manually planned loads)</td>\n",
       "      <td>8.8</td>\n",
       "      <td>23.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K13b</td>\n",
       "      <td>K13b Release to Warehouse &amp; Complete Picking W...</td>\n",
       "      <td>18.7</td>\n",
       "      <td>61.6</td>\n",
       "      <td>31.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>258</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K14b</td>\n",
       "      <td>K13b Release to Warehouse &amp; Complete Picking W...</td>\n",
       "      <td>11.5</td>\n",
       "      <td>158.6</td>\n",
       "      <td>24.9</td>\n",
       "      <td>12.8</td>\n",
       "      <td>657</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K15</td>\n",
       "      <td>K15 aDSD Load confirmation</td>\n",
       "      <td>19.8</td>\n",
       "      <td>94.9</td>\n",
       "      <td>35.7</td>\n",
       "      <td>15.4</td>\n",
       "      <td>153</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K18</td>\n",
       "      <td>K18 Import Actual Statistical entries, into Co...</td>\n",
       "      <td>24.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  KPI_no                                        KPI Process  Average    Max  \\\n",
       "0    K11         K11 Send Load to Roadnet load for Planning      3.5   11.4   \n",
       "1    K12            K12 Receive load from Roadnet into D365     57.7   74.1   \n",
       "2    K13  K13 Release to Warehouse (manually planned loads)     27.3   81.4   \n",
       "3    K14  K13 Release to Warehouse (manually planned loads)      8.8   23.1   \n",
       "4   K13b  K13b Release to Warehouse & Complete Picking W...     18.7   61.6   \n",
       "5   K14b  K13b Release to Warehouse & Complete Picking W...     11.5  158.6   \n",
       "6    K15                         K15 aDSD Load confirmation     19.8   94.9   \n",
       "7    K18  K18 Import Actual Statistical entries, into Co...     24.4   24.4   \n",
       "\n",
       "   90th_%    SD  Successful Runs  Incomplete Runs  \n",
       "0     4.5   1.3               91               12  \n",
       "1    71.1  22.8                6                6  \n",
       "2    48.2  22.9               10                3  \n",
       "3    18.3   6.9               10                3  \n",
       "4    31.9   9.9              258               32  \n",
       "5    24.9  12.8              657               32  \n",
       "6    35.7  15.4              153               30  \n",
       "7    24.4   NaN                1                1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/execution/' + rundate +  '_kpi_results.xlsx'\n",
    "kpi_results.to_excel(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Stop right here!",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Stop right here!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wikus/code/ipt3/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "raise SystemExit(\"Stop right here!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert this to prevent the cells below from trying to write to the sql table\n",
    "raise SystemExit(\"Stop right here!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
