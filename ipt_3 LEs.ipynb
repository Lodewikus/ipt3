{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import SAP data previously mapped for ZA1\n",
    "\n",
    "15Dec_D365_orders_ZA1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(\"./data/ZA/15Dec_D365_orders_ZA1.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data for other Legal Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = 'MZ'\n",
    "path = './data/'+ LE + '/15Dec_D365_orders_' + LE + '.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_feather(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31442 entries, 0 to 31441\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   ActivityType              31442 non-null  object\n",
      " 1   Order Number              31442 non-null  int64 \n",
      " 2   BaseDate                  31442 non-null  object\n",
      " 3   BaseHour                  31442 non-null  int64 \n",
      " 4   Cases                     31442 non-null  int64 \n",
      " 5   Bill I                    31393 non-null  object\n",
      " 6   Source Channel            31442 non-null  object\n",
      " 7   Order Category            31442 non-null  object\n",
      " 8   Material No               31442 non-null  object\n",
      " 9   MOD                       31442 non-null  int64 \n",
      " 10  WAREHOUSELOCATIONID       31442 non-null  object\n",
      " 11  D365_Del_Loc              31442 non-null  object\n",
      " 12  CIC Order Placement Rule  31442 non-null  object\n",
      " 13  D365_Account_Name         31442 non-null  object\n",
      " 14  site_id                   31442 non-null  object\n",
      " 15  D365_ItemNo               31442 non-null  int64 \n",
      " 16  Material_Description      31442 non-null  object\n",
      " 17  D365_Cust_No              31442 non-null  int64 \n",
      "dtypes: int64(6), object(12)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/' + LE + '/15Dec_D365_orders_' + LE + '.csv'\n",
    "df5.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_count = pd.DataFrame(columns=['Activity type','Hour','Sales orders', 'Order lines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CSVs per activity type, and for the 13th and 20th hours\n",
    "# 1ORDERCREATION\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 12))\n",
    "peak_order_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_12h_' + LE + '.csv'\n",
    "peak_order_hour.to_csv(path,index=False)\n",
    "\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 19))\n",
    "peak_settlement_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_19h_' + LE + '.csv'\n",
    "peak_settlement_hour.to_csv('output/15Dec_D365_orders_1ORDERCREATION_19h.csv',index=False)\n",
    "\n",
    "# 2PLAN\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "new_row = {'Activity type': '2PLAN', 'Hour': '12', 'Sales orders': len(df5_1['Order Number'].unique()), 'Order lines': len(df5_1)}\n",
    "rec_count = pd.concat([rec_count, pd.DataFrame([new_row])])\n",
    "\n",
    "\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "new_row = {'Activity type': '2PLAN', 'Hour': '19', 'Sales orders': len(df5_1['Order Number'].unique()), 'Order lines': len(df5_1)}\n",
    "rec_count = pd.concat([rec_count, pd.DataFrame([new_row])])\n",
    "\n",
    "\n",
    "# 3DESPATCH\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "new_row = {'Activity type': '3DESPATCH', 'Hour': '12', 'Sales orders': len(df5_1['Order Number'].unique()), 'Order lines': len(df5_1)}\n",
    "rec_count = pd.concat([rec_count, pd.DataFrame([new_row])])\n",
    "\n",
    "\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "new_row = {'Activity type': '3DESPATCH', 'Hour': '19', 'Sales orders': len(df5_1['Order Number'].unique()), 'Order lines': len(df5_1)}\n",
    "rec_count = pd.concat([rec_count, pd.DataFrame([new_row])])\n",
    "\n",
    "\n",
    "# 4SETTLE\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "new_row = {'Activity type': '4SETTLE', 'Hour': '12', 'Sales orders': len(df5_1['Order Number'].unique()), 'Order lines': len(df5_1)}\n",
    "rec_count = pd.concat([rec_count, pd.DataFrame([new_row])])\n",
    "\n",
    "\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "new_row = {'Activity type': '4SETTLE', 'Hour': '19', 'Sales orders': len(df5_1['Order Number'].unique()), 'Order lines': len(df5_1)}\n",
    "rec_count = pd.concat([rec_count, pd.DataFrame([new_row])])\n",
    "\n",
    "\n",
    "# 5TRADERETURNS\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = peak_order_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "x.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a CSV for the rest of the hours, that is, excluding the 13th and 20th hours.  This set can be used to do preparation testing.\n",
    "mask = ((df5['BaseHour'] != 12) & (df5['BaseHour'] != 19))\n",
    "df5_1 = df5[mask]\n",
    "df5_1.to_csv('output/15Dec_D365_orders_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = peak_settlement_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "y.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_count = rec_count.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales order volumes for peak order hour (12h00 to 13h00):\n",
      "  Source Channel  Sales orders  Order lines\n",
      "0            SFA            70          777\n",
      "1       Voice in             1            1\n",
      "\n",
      "\n",
      "Sales order volumes for peak settlement hour (19h00 to 20h00):\n",
      "  Source Channel  Sales orders  Order lines\n",
      "0            SFA             4           33\n",
      "\n",
      "\n",
      "Sales order volumes data staging in F&O:\n",
      "  Activity type Hour Sales orders Order lines\n",
      "0         2PLAN   12           38         127\n",
      "1         2PLAN   19           40         341\n",
      "2     3DESPATCH   12           41         282\n",
      "3     3DESPATCH   19           28         143\n",
      "4       4SETTLE   12           35         195\n",
      "5       4SETTLE   19          215        1358\n"
     ]
    }
   ],
   "source": [
    "print('Sales order volumes for peak order hour (12h00 to 13h00):')\n",
    "print(x)\n",
    "print('\\n\\nSales order volumes for peak settlement hour (19h00 to 20h00):')\n",
    "print(y)\n",
    "print('\\n\\nSales order volumes data staging in F&O:')\n",
    "print(rec_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above, generate a file that contains just one record per customer, so that we can use this to verify that each customer master record works\n",
    "df5_2 = df5_1.drop_duplicates(subset=['D365_Cust_No'],keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f5_2.to_csv('output/15Dec_D365_single_line_per_customer_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "File generation completed",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m File generation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wikus/code/ipt3/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "raise SystemExit(\"File generation completed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create file for stock journals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a journal line item per item per warehouse, with a replenishment_qty that is 100x the sum of order quantities (Cases) per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this dataframe before dropping columns not needed for order creation\n",
    "stock_journal = df5[['D365_ItemNo', 'D365_Del_Loc','Cases']]\n",
    "stock_journal = stock_journal.groupby(['D365_Del_Loc', 'D365_ItemNo'],as_index=False).sum('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['replenishment_qty'] = stock_journal['Cases']*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with warehouse dataframe to get Financial Dimensions per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['INVENTORYSTATUSID'] = 'Available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warehouses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wikus/code/ipt3/ipt_3.ipynb Cell 103\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stock_journal1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     stock_journal,\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     warehouses,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     on\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD365_Del_Loc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD365_Del_Loc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     left_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     right_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     suffixes\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m_x\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_y\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     indicator\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     validate\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/wikus/code/ipt3/ipt_3.ipynb#Y203sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warehouses' is not defined"
     ]
    }
   ],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "    stock_journal,\n",
    "    warehouses,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='D365_Del_Loc',\n",
    "    right_on='D365_Del_Loc',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1.rename(columns={'Financial_Dimension': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1.drop(columns={'Cases', 'D365_WH_NAME', 'SAP_WH_NAME','Cost_Centre'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = stock_journal1.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a sequential index for LineNumber\n",
    "line_number = range(1,stock_journal1.last_valid_index()+2,1)\n",
    "stock_journal1['LINENUMBER']=line_number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a journal number per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = pd.DataFrame(stock_journal1['D365_WH_NO'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number.rename(columns={0: 'D365_WH_NO'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = journal_number.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_valid_jnumber = input('Enter first valid journal number (numbers only)')\n",
    "#first_valid_jnumber = '76517'\n",
    "first_valid_jnumber = int(first_valid_jnumber)\n",
    "#ZA10700076636 - 24 Jan 2023\n",
    "#ZA10700084774 - 14 Mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(first_valid_jnumber,first_valid_jnumber+journal_number.last_valid_index()+1,1)\n",
    "journal_number['JOURNALNUMBER']=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number['JOURNALNUMBER'] = journal_number['JOURNALNUMBER'].astype(str)\n",
    "journal_number['JOURNALNUMBER'] = 'ZA1070' +  + journal_number['JOURNALNUMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "   stock_journal1,\n",
    "   journal_number,\n",
    "   how=\"inner\",\n",
    "   on=None,\n",
    "   left_on='D365_WH_NO',\n",
    "   right_on='D365_WH_NO',\n",
    "   left_index=False,\n",
    "   right_index=False,\n",
    "   sort=True,\n",
    "   suffixes=(\"_x\", \"_y\"),\n",
    "   copy=True,\n",
    "   indicator=False,\n",
    "   validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1['ITEMBATCHNUMBER']='1'\n",
    "stock_journal1['JOURNALNAMEID']='ADJ_WHS'\n",
    "stock_journal1['TRANSACTIONDATE']= pd.to_datetime('today').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1.to_csv('output/stock_journal.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = df5[['D365_ItemNo', 'Material_Description']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 378 entries, 0 to 782792\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           378 non-null    object\n",
      " 1   Material_Description  378 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.9+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items.to_excel('data/unique_items.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 873140 entries, 0 to 903661\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   ActivityType              873140 non-null  object        \n",
      " 1   Order Number              873140 non-null  int64         \n",
      " 2   Material_Description      873140 non-null  object        \n",
      " 3   BaseDate                  873140 non-null  datetime64[ns]\n",
      " 4   BaseHour                  873140 non-null  int64         \n",
      " 5   Cases                     873140 non-null  int64         \n",
      " 6   Bill I                    869104 non-null  object        \n",
      " 7   Source Channel            873140 non-null  object        \n",
      " 8   Order Category            873140 non-null  object        \n",
      " 9   D365_ItemNo               873140 non-null  object        \n",
      " 10  Material No               873140 non-null  object        \n",
      " 11  MOD                       873140 non-null  object        \n",
      " 12  site_id                   873140 non-null  object        \n",
      " 13  WAREHOUSELOCATIONID       873140 non-null  object        \n",
      " 14  D365_Del_Loc              873140 non-null  object        \n",
      " 15  D365_Cust_No              873140 non-null  int64         \n",
      " 16  CIC Order Placement Rule  873140 non-null  object        \n",
      " 17  D365_Account_Name         873140 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(13)\n",
      "memory usage: 126.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88 entries, 0 to 87\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   SAP_WH_NAME          88 non-null     object\n",
      " 1   D365_WH_NAME         88 non-null     object\n",
      " 2   D365_WH_NO           88 non-null     object\n",
      " 3   site_id              88 non-null     object\n",
      " 4   WAREHOUSELOCATIONID  88 non-null     object\n",
      " 5   Cost_Centre          88 non-null     object\n",
      " 6   Financial_Dimension  88 non-null     object\n",
      " 7   D365_Del_Loc         88 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "warehouses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Cartesian product\n",
    "price_update = unique_items.assign(key=1).merge(warehouses.assign(key=1), on='key').drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33264 entries, 0 to 33263\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           33264 non-null  object\n",
      " 1   Material_Description  33264 non-null  object\n",
      " 2   SAP_WH_NAME           33264 non-null  object\n",
      " 3   D365_WH_NAME          33264 non-null  object\n",
      " 4   D365_WH_NO            33264 non-null  object\n",
      " 5   site_id               33264 non-null  object\n",
      " 6   WAREHOUSELOCATIONID   33264 non-null  object\n",
      " 7   Cost_Centre           33264 non-null  object\n",
      " 8   Financial_Dimension   33264 non-null  object\n",
      " 9   D365_Del_Loc          33264 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "price_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update.drop(columns={'Material_Description', 'SAP_WH_NAME', 'D365_WH_NAME', 'D365_WH_NO', 'WAREHOUSELOCATIONID', 'Cost_Centre', 'Financial_Dimension', 'D365_Del_Loc'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update.rename(columns={'D365_ItemNo': 'ItemNumber', 'site_id': 'PriceSiteId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update = price_update.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update['Price'] = 42285\n",
    "price_update['PriceQuantity'] = 1000\n",
    "price_update['PriceType'] = 'Cost'\n",
    "price_update['CostingVersion'] = 'Std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update.to_excel('output/price_update.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
