{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import SAP data previously mapped for ZA1\n",
    "\n",
    "15Dec_D365_orders_ZA1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5 = pd.read_csv(\"./data/ZA1/15Dec_D365_orders_ZA1.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data for other Legal Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = input('Enter the legal entity company code')\n",
    "# NA1, MZ1, UG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'+ LE + '/15Dec_D365_orders_' + LE + '.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_feather(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 370721 entries, 105098 to 182777\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   ActivityType              370721 non-null  object        \n",
      " 1   Order Number              370721 non-null  int64         \n",
      " 2   BaseDate                  370721 non-null  datetime64[ns]\n",
      " 3   BaseHour                  370721 non-null  int64         \n",
      " 4   Cases                     370721 non-null  int64         \n",
      " 5   Bill I                    368347 non-null  object        \n",
      " 6   Source Channel            370721 non-null  object        \n",
      " 7   Order Category            370721 non-null  object        \n",
      " 8   Material No               370721 non-null  object        \n",
      " 9   MOD                       370721 non-null  int64         \n",
      " 10  WAREHOUSELOCATIONID       370721 non-null  object        \n",
      " 11  CIC Order Placement Rule  370721 non-null  object        \n",
      " 12  D365_Account_Name         370721 non-null  object        \n",
      " 13  D365_Del_Loc              370721 non-null  object        \n",
      " 14  D365_ItemNo               370721 non-null  int64         \n",
      " 15  Material_Description      370721 non-null  object        \n",
      " 16  D365_Cust_No              370721 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(10)\n",
      "memory usage: 50.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.drop(columns={'Cases'}, inplace=True, axis=1)\n",
    "df5['Cases'] = np.random.randint(1, 4290, size=len(df5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/' + LE + '/15Dec_D365_orders_' + LE + '.csv'\n",
    "df5.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CSVs per activity type, and for the 13th and 20th hours\n",
    "# 1ORDERCREATION\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 12))\n",
    "peak_order_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_12h_' + LE + '.csv'\n",
    "peak_order_hour.to_csv(path,index=False)\n",
    "\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 19))\n",
    "peak_settlement_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_19h_' + LE + '.csv'\n",
    "peak_settlement_hour.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "# 2PLAN - 12H\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4PLAN - 12H\n",
    "df5_1['MOD'] = '4'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4PLAN_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 2PLAN - 19H\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4PLAN - 19H\n",
    "df5_1['MOD'] = '4'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4PLAN_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 3DESPATCH\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "# 4SETTLE - 12H\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5SETTLE - 12H\n",
    "df5_1['MOD'] = '5'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5SETTLE_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4SETTLE - 19H\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5SETTLE - 19H\n",
    "df5_1['MOD'] = '5'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5SETTLE_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5TRADERETURNS\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = peak_order_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "x.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a CSV for the rest of the hours, that is, excluding the 13th and 20th hours.  This set can be used to do preparation testing.\n",
    "mask = ((df5['BaseHour'] != 12) & (df5['BaseHour'] != 19))\n",
    "df5_1 = df5[mask]\n",
    "df5_1.to_csv('output/15Dec_D365_orders_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = peak_settlement_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "y.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above, generate a file that contains just one record per customer, so that we can use this to verify that each customer master record works\n",
    "df5_2 = df5_1.drop_duplicates(subset=['D365_Cust_No'],keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f5_2.to_csv('output/15Dec_D365_single_line_per_customer_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise SystemExit(\"File generation completed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create file for stock journals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import warehouse files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LE == 'NA1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/NA1/NA1_Validated  IPT3 Warehouse Export  NA1 Warehouses.csv\", delimiter=\",\")\n",
    "    LE_Warehouses.rename(columns={'D365_Del_Location': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'WAREHOUSEID': 'D365_WH_NO', 'OPERATIONALSITEID': 'site_id', 'CCBWMSLOCATIONIDDEFAULTRECEIPT': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'CCBWAREHOUSETYPE', 'CCBFINANCECOSTCENTER', 'AREADVANCEDWAREHOUSEMANAGEMENTPROCESSESENABLED', 'D365_WH_NAME', 'CCBWAREHOUSECOSTCENTER'}, inplace=True, axis=1)\n",
    "    #D365_Del_Location\n",
    "\n",
    "if LE == 'MZ1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/MZ1/IPT3 MZ1 PERF01 Warehouse.csv\", delimiter=\",\")\n",
    "    LE_Warehouses.rename(columns={'D365DELIVERYLOCATION': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'WAREHOUSEID': 'D365_WH_NO', 'OPERATIONALSITEID': 'site_id', 'CCBWMSLOCATIONIDDEFAULTRECEIPT': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'CCBWAREHOUSETYPE', 'CCBFINANCECOSTCENTER', 'AREADVANCEDWAREHOUSEMANAGEMENTPROCESSESENABLED', 'D365WHNAME', 'CCBWAREHOUSECOSTCENTER'}, inplace=True, axis=1)\n",
    "if LE == 'UG1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/UG1/IPT3 WMS UG1-Warehouses.csv\", delimiter=\",\")    \n",
    "    LE_Warehouses.rename(columns={'D365_Del_Loc': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'Warehouse': 'D365_WH_NO', 'Site ID': 'site_id', 'Location': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'FinanceCost centre', 'Cost Centre'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warehouses = LE_Warehouses.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   D365_WH_NO           3 non-null      object\n",
      " 1   Unnamed: 1           3 non-null      object\n",
      " 2   site_id              3 non-null      object\n",
      " 3   WAREHOUSELOCATIONID  3 non-null      object\n",
      " 4   Financial_Dimension  3 non-null      object\n",
      " 5   D365_Del_Loc         3 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 272.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "warehouses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D365_WH_NO</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>site_id</th>\n",
       "      <th>WAREHOUSELOCATIONID</th>\n",
       "      <th>Financial_Dimension</th>\n",
       "      <th>D365_Del_Loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UG010B</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG010</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F005--UG1L015--UG010-</td>\n",
       "      <td>UG1-UG010B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UG011B</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG011</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F003--UG1L008--UG011-</td>\n",
       "      <td>UG1-UG011B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UG012B</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG012</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F003--UG1L003--UG012-</td>\n",
       "      <td>UG1-UG012B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  D365_WH_NO Unnamed: 1 site_id WAREHOUSELOCATIONID  \\\n",
       "0     UG010B        Yes   UG010               GEN01   \n",
       "1     UG011B        Yes   UG011               GEN01   \n",
       "2     UG012B        Yes   UG012               GEN01   \n",
       "\n",
       "              Financial_Dimension D365_Del_Loc  \n",
       "0  -BU01-UG1F005--UG1L015--UG010-   UG1-UG010B  \n",
       "1  -BU01-UG1F003--UG1L008--UG011-   UG1-UG011B  \n",
       "2  -BU01-UG1F003--UG1L003--UG012-   UG1-UG012B  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a journal line item per item per warehouse, with a replenishment_qty that is 100x the sum of order quantities (Cases) per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this dataframe before dropping columns not needed for order creation\n",
    "stock_journal = df5[['D365_ItemNo', 'D365_Del_Loc','Cases']]\n",
    "stock_journal = stock_journal.groupby(['D365_Del_Loc', 'D365_ItemNo'],as_index=False).sum('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D365_Del_Loc</th>\n",
       "      <th>D365_ItemNo</th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1010</td>\n",
       "      <td>3305156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1040</td>\n",
       "      <td>3870882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1062</td>\n",
       "      <td>2071580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1108</td>\n",
       "      <td>1861446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1271</td>\n",
       "      <td>7942727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>UG1-UG012B</td>\n",
       "      <td>11135</td>\n",
       "      <td>1816821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>UG1-UG012B</td>\n",
       "      <td>11136</td>\n",
       "      <td>3960937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>UG1-UG012B</td>\n",
       "      <td>11137</td>\n",
       "      <td>2845257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>UG1-UG012B</td>\n",
       "      <td>11165</td>\n",
       "      <td>1356581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>UG1-UG012B</td>\n",
       "      <td>11166</td>\n",
       "      <td>1246499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    D365_Del_Loc  D365_ItemNo    Cases\n",
       "0     UG1-UG010B         1010  3305156\n",
       "1     UG1-UG010B         1040  3870882\n",
       "2     UG1-UG010B         1062  2071580\n",
       "3     UG1-UG010B         1108  1861446\n",
       "4     UG1-UG010B         1271  7942727\n",
       "..           ...          ...      ...\n",
       "238   UG1-UG012B        11135  1816821\n",
       "239   UG1-UG012B        11136  3960937\n",
       "240   UG1-UG012B        11137  2845257\n",
       "241   UG1-UG012B        11165  1356581\n",
       "242   UG1-UG012B        11166  1246499\n",
       "\n",
       "[243 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['replenishment_qty'] = stock_journal['Cases']*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with warehouse dataframe to get Financial Dimensions per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['INVENTORYSTATUSID'] = 'Available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "    stock_journal,\n",
    "    warehouses,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='D365_Del_Loc',\n",
    "    right_on='D365_Del_Loc',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1.rename(columns={'Financial_Dimension': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 243 entries, 0 to 242\n",
      "Data columns (total 10 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   D365_Del_Loc                        243 non-null    object\n",
      " 1   D365_ItemNo                         243 non-null    int64 \n",
      " 2   Cases                               243 non-null    int64 \n",
      " 3   replenishment_qty                   243 non-null    int64 \n",
      " 4   INVENTORYSTATUSID                   243 non-null    object\n",
      " 5   D365_WH_NO                          243 non-null    object\n",
      " 6   Unnamed: 1                          243 non-null    object\n",
      " 7   site_id                             243 non-null    object\n",
      " 8   WAREHOUSELOCATIONID                 243 non-null    object\n",
      " 9   DEFAULTLEDGERDIMENSIONDISPLAYVALUE  243 non-null    object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 19.1+ KB\n"
     ]
    }
   ],
   "source": [
    "stock_journal1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_journal1.drop(columns={'Cases', 'D365_WH_NAME', 'SAP_WH_NAME','Cost_Centre'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = stock_journal1.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    D365_Del_Loc  D365_ItemNo    Cases  replenishment_qty INVENTORYSTATUSID  \\\n",
      "0     UG1-UG010B         1010  3305156          330515600         Available   \n",
      "58    UG1-UG010B        10314  2747427          274742700         Available   \n",
      "57    UG1-UG010B        10306  5980244          598024400         Available   \n",
      "56    UG1-UG010B        10208  8327419          832741900         Available   \n",
      "55    UG1-UG010B        10082  1873708          187370800         Available   \n",
      "..           ...          ...      ...                ...               ...   \n",
      "185   UG1-UG012B         3040  2253232          225323200         Available   \n",
      "184   UG1-UG012B         3010  2065016          206501600         Available   \n",
      "183   UG1-UG012B         2376  2972404          297240400         Available   \n",
      "181   UG1-UG012B         2205  2061606          206160600         Available   \n",
      "242   UG1-UG012B        11166  1246499          124649900         Available   \n",
      "\n",
      "    D365_WH_NO Unnamed: 1 site_id WAREHOUSELOCATIONID  \\\n",
      "0       UG010B        Yes   UG010               GEN01   \n",
      "58      UG010B        Yes   UG010               GEN01   \n",
      "57      UG010B        Yes   UG010               GEN01   \n",
      "56      UG010B        Yes   UG010               GEN01   \n",
      "55      UG010B        Yes   UG010               GEN01   \n",
      "..         ...        ...     ...                 ...   \n",
      "185     UG012B        Yes   UG012               GEN01   \n",
      "184     UG012B        Yes   UG012               GEN01   \n",
      "183     UG012B        Yes   UG012               GEN01   \n",
      "181     UG012B        Yes   UG012               GEN01   \n",
      "242     UG012B        Yes   UG012               GEN01   \n",
      "\n",
      "    DEFAULTLEDGERDIMENSIONDISPLAYVALUE  \n",
      "0       -BU01-UG1F005--UG1L015--UG010-  \n",
      "58      -BU01-UG1F005--UG1L015--UG010-  \n",
      "57      -BU01-UG1F005--UG1L015--UG010-  \n",
      "56      -BU01-UG1F005--UG1L015--UG010-  \n",
      "55      -BU01-UG1F005--UG1L015--UG010-  \n",
      "..                                 ...  \n",
      "185     -BU01-UG1F003--UG1L003--UG012-  \n",
      "184     -BU01-UG1F003--UG1L003--UG012-  \n",
      "183     -BU01-UG1F003--UG1L003--UG012-  \n",
      "181     -BU01-UG1F003--UG1L003--UG012-  \n",
      "242     -BU01-UG1F003--UG1L003--UG012-  \n",
      "\n",
      "[243 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_journal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a sequential index for LineNumber\n",
    "line_number = range(1,stock_journal1.last_valid_index()+2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock_journal1['LINENUMBER']=line_number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a journal number per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = pd.DataFrame(stock_journal1['D365_WH_NO'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number.rename(columns={0: 'D365_WH_NO'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = journal_number.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_valid_jnumber = input('Enter first valid journal number (numbers only)')\n",
    "#first_valid_jnumber = '76517'\n",
    "first_valid_jnumber = int(first_valid_jnumber)\n",
    "#ZA10700076636 - 24 Jan 2023\n",
    "#ZA10700084774 - 14 Mar\n",
    "# 2 Oct 2023\n",
    "# NA1-000031\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(first_valid_jnumber,first_valid_jnumber+journal_number.last_valid_index()+1,1)\n",
    "journal_number['JOURNALNUMBER']=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number['journal_str'] = journal_number['JOURNALNUMBER'].apply(lambda x: str(x).zfill(6))\n",
    "#journal_number['JOURNALNUMBER'] = journal_number['JOURNALNUMBER'].astype(str)\n",
    "journal_number['journal_str'] = LE + '-' + journal_number['journal_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "   stock_journal1,\n",
    "   journal_number,\n",
    "   how=\"inner\",\n",
    "   on=None,\n",
    "   left_on='D365_WH_NO',\n",
    "   right_on='D365_WH_NO',\n",
    "   left_index=False,\n",
    "   right_index=False,\n",
    "   sort=True,\n",
    "   suffixes=(\"_x\", \"_y\"),\n",
    "   copy=True,\n",
    "   indicator=False,\n",
    "   validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1['ITEMBATCHNUMBER']='1'\n",
    "stock_journal1['JOURNALNAMEID']='ADJ_WHS'\n",
    "stock_journal1['TRANSACTIONDATE']= pd.to_datetime('today').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/' + LE + '/stock_journal_' + LE + '.csv'\n",
    "stock_journal1.to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = df5[['D365_ItemNo', 'Material_Description']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 81 entries, 105098 to 607902\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           81 non-null     int64 \n",
      " 1   Material_Description  81 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_items.to_excel('data/unique_items.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 370721 entries, 105098 to 182777\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   ActivityType              370721 non-null  object        \n",
      " 1   Order Number              370721 non-null  int64         \n",
      " 2   BaseDate                  370721 non-null  datetime64[ns]\n",
      " 3   BaseHour                  370721 non-null  int64         \n",
      " 4   Bill I                    368347 non-null  object        \n",
      " 5   Source Channel            370721 non-null  object        \n",
      " 6   Order Category            370721 non-null  object        \n",
      " 7   Material No               370721 non-null  object        \n",
      " 8   MOD                       370721 non-null  int64         \n",
      " 9   WAREHOUSELOCATIONID       370721 non-null  object        \n",
      " 10  CIC Order Placement Rule  370721 non-null  object        \n",
      " 11  D365_Account_Name         370721 non-null  object        \n",
      " 12  D365_Del_Loc              370721 non-null  object        \n",
      " 13  D365_ItemNo               370721 non-null  int64         \n",
      " 14  Material_Description      370721 non-null  object        \n",
      " 15  D365_Cust_No              370721 non-null  int64         \n",
      " 16  Cases                     370721 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(10)\n",
      "memory usage: 50.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   D365_WH_NO           3 non-null      object\n",
      " 1   Unnamed: 1           3 non-null      object\n",
      " 2   site_id              3 non-null      object\n",
      " 3   WAREHOUSELOCATIONID  3 non-null      object\n",
      " 4   Financial_Dimension  3 non-null      object\n",
      " 5   D365_Del_Loc         3 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 272.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "warehouses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Cartesian product\n",
    "price_update = unique_items.assign(key=1).merge(warehouses.assign(key=1), on='key').drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 243 entries, 0 to 242\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           243 non-null    int64 \n",
      " 1   Material_Description  243 non-null    object\n",
      " 2   D365_WH_NO            243 non-null    object\n",
      " 3   Unnamed: 1            243 non-null    object\n",
      " 4   site_id               243 non-null    object\n",
      " 5   WAREHOUSELOCATIONID   243 non-null    object\n",
      " 6   Financial_Dimension   243 non-null    object\n",
      " 7   D365_Del_Loc          243 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 15.3+ KB\n"
     ]
    }
   ],
   "source": [
    "price_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_update.drop(columns={'Material_Description', 'SAP_WH_NAME', 'D365_WH_NAME', 'D365_WH_NO', 'WAREHOUSELOCATIONID', 'Cost_Centre', 'Financial_Dimension', 'D365_Del_Loc'}, inplace=True, axis=1)\n",
    "price_update.drop(columns={'Material_Description', 'D365_WH_NO', 'WAREHOUSELOCATIONID', 'D365_Del_Loc'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update.rename(columns={'D365_ItemNo': 'ItemNumber', 'site_id': 'PriceSiteId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update = price_update.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update['Price'] = 42285\n",
    "price_update['PriceQuantity'] = 1000\n",
    "price_update['PriceType'] = 'Cost'\n",
    "price_update['CostingVersion'] = 'Std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_update.to_excel('output/price_update.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
