{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import SAP data previously mapped for ZA1\n",
    "\n",
    "15Dec_D365_orders_ZA1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5 = pd.read_csv(\"./data/ZA1/15Dec_D365_orders_ZA1.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data for other Legal Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = input('Enter the legal entity company code')\n",
    "# NA1, MZ1, UG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'+ LE + '/15Dec_D365_orders_' + LE + '.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_feather(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 427241 entries, 119142 to 209929\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   ActivityType              427241 non-null  object        \n",
      " 1   Order Number              427241 non-null  int64         \n",
      " 2   BaseDate                  427241 non-null  datetime64[ns]\n",
      " 3   BaseHour                  427241 non-null  int64         \n",
      " 4   Cases                     427241 non-null  int64         \n",
      " 5   Bill I                    424385 non-null  object        \n",
      " 6   Source Channel            427241 non-null  object        \n",
      " 7   Order Category            427241 non-null  object        \n",
      " 8   Material No               427241 non-null  object        \n",
      " 9   MOD                       427241 non-null  int64         \n",
      " 10  WAREHOUSELOCATIONID       427241 non-null  object        \n",
      " 11  CIC Order Placement Rule  427241 non-null  object        \n",
      " 12  D365_Account_Name         427241 non-null  object        \n",
      " 13  D365_Del_Loc              427241 non-null  object        \n",
      " 14  D365_ItemNo               427241 non-null  int64         \n",
      " 15  Material_Description      427241 non-null  object        \n",
      " 16  D365_Cust_No              427241 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(10)\n",
      "memory usage: 58.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/' + LE + '/15Dec_D365_orders_' + LE + '.csv'\n",
    "df5.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CSVs per activity type, and for the 13th and 20th hours\n",
    "# 1ORDERCREATION\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 12))\n",
    "peak_order_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_12h_' + LE + '.csv'\n",
    "peak_order_hour.to_csv(path,index=False)\n",
    "\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 19))\n",
    "peak_settlement_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_19h_' + LE + '.csv'\n",
    "peak_settlement_hour.to_csv('output/15Dec_D365_orders_1ORDERCREATION_19h.csv',index=False)\n",
    "\n",
    "\n",
    "# 2PLAN - 12H\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4PLAN - 12H\n",
    "df5_1['MOD'] = '4'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4PLAN_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 2PLAN - 19H\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4PLAN - 19H\n",
    "df5_1['MOD'] = '4'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4PLAN_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 3DESPATCH\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "# 4SETTLE - 12H\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5SETTLE - 12H\n",
    "df5_1['MOD'] = '5'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5SETTLE_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4SETTLE - 19H\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5SETTLE - 19H\n",
    "df5_1['MOD'] = '5'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5SETTLE_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5TRADERETURNS\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = peak_order_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "x.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a CSV for the rest of the hours, that is, excluding the 13th and 20th hours.  This set can be used to do preparation testing.\n",
    "mask = ((df5['BaseHour'] != 12) & (df5['BaseHour'] != 19))\n",
    "df5_1 = df5[mask]\n",
    "df5_1.to_csv('output/15Dec_D365_orders_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = peak_settlement_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "y.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above, generate a file that contains just one record per customer, so that we can use this to verify that each customer master record works\n",
    "df5_2 = df5_1.drop_duplicates(subset=['D365_Cust_No'],keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f5_2.to_csv('output/15Dec_D365_single_line_per_customer_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise SystemExit(\"File generation completed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create file for stock journals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import warehouse files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LE == 'NA1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/NA1/NA1_Validated  IPT3 Warehouse Export  NA1 Warehouses.csv\", delimiter=\",\")\n",
    "    LE_Warehouses.rename(columns={'D365_Del_Location': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'WAREHOUSEID': 'D365_WH_NO', 'OPERATIONALSITEID': 'site_id', 'CCBWMSLOCATIONIDDEFAULTRECEIPT': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'CCBWAREHOUSETYPE', 'CCBFINANCECOSTCENTER', 'AREADVANCEDWAREHOUSEMANAGEMENTPROCESSESENABLED', 'D365_WH_NAME', 'CCBWAREHOUSECOSTCENTER'}, inplace=True, axis=1)\n",
    "    #D365_Del_Location\n",
    "\n",
    "if LE == 'MZ1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/MZ1/IPT3 MZ1 PERF01 Warehouse.csv\", delimiter=\",\")\n",
    "    LE_Warehouses.rename(columns={'D365DELIVERYLOCATION': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'WAREHOUSEID': 'D365_WH_NO', 'OPERATIONALSITEID': 'site_id', 'CCBWMSLOCATIONIDDEFAULTRECEIPT': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'CCBWAREHOUSETYPE', 'CCBFINANCECOSTCENTER', 'AREADVANCEDWAREHOUSEMANAGEMENTPROCESSESENABLED', 'D365WHNAME', 'CCBWAREHOUSECOSTCENTER'}, inplace=True, axis=1)\n",
    "if LE == 'UG1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/UG1/IPT3 WMS UG1-Warehouses.csv\", delimiter=\",\")    \n",
    "    LE_Warehouses.rename(columns={'D365_Del_Loc': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'Warehouse': 'D365_WH_NO', 'Site ID': 'site_id', 'Location': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'FinanceCost centre', 'Cost Centre'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warehouses = LE_Warehouses.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   site_id              7 non-null      object\n",
      " 1   WAREHOUSELOCATIONID  7 non-null      object\n",
      " 2   D365_WH_NO           7 non-null      object\n",
      " 3   FINANCIALDIMENSION   7 non-null      object\n",
      " 4   D365_Del_Loc         7 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 408.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "warehouses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>WAREHOUSELOCATIONID</th>\n",
       "      <th>D365_WH_NO</th>\n",
       "      <th>FINANCIALDIMENSION</th>\n",
       "      <th>D365_Del_Loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MZ010</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>MZ010B</td>\n",
       "      <td>-BU01-MZ1F004--MZ1L004--MZ010-</td>\n",
       "      <td>MZ1-MZ010B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MZ010</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>MZ010Q</td>\n",
       "      <td>-BU01-MZ1F004----MZ010-</td>\n",
       "      <td>MZ1-MZ010Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MZ011</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>MZ011B</td>\n",
       "      <td>-BU01-MZ1F004--MZ1L026--MZ011-</td>\n",
       "      <td>MZ1-MZ011B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MZ011</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>MZ011Q</td>\n",
       "      <td>-BU01-MZ1F004----MZ011-</td>\n",
       "      <td>MZ1-MZ011Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MZ012</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>MZ012B</td>\n",
       "      <td>-BU01-MZ1F004--MZ1L017--MZ012-</td>\n",
       "      <td>MZ1-MZ012B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MZ012</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>MZ012Q</td>\n",
       "      <td>-BU01-MZ1F004----MZ012-</td>\n",
       "      <td>MZ1-MZ012Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MZ013</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>MZ013B</td>\n",
       "      <td>-BU01-MZ1F004----MZ013-</td>\n",
       "      <td>MZ1-MZ013B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site_id WAREHOUSELOCATIONID D365_WH_NO              FINANCIALDIMENSION  \\\n",
       "0   MZ010               GEN01     MZ010B  -BU01-MZ1F004--MZ1L004--MZ010-   \n",
       "1   MZ010               GEN01     MZ010Q         -BU01-MZ1F004----MZ010-   \n",
       "2   MZ011               GEN01     MZ011B  -BU01-MZ1F004--MZ1L026--MZ011-   \n",
       "3   MZ011               GEN01     MZ011Q         -BU01-MZ1F004----MZ011-   \n",
       "4   MZ012               GEN01     MZ012B  -BU01-MZ1F004--MZ1L017--MZ012-   \n",
       "5   MZ012               GEN01     MZ012Q         -BU01-MZ1F004----MZ012-   \n",
       "6   MZ013               GEN01     MZ013B         -BU01-MZ1F004----MZ013-   \n",
       "\n",
       "  D365_Del_Loc  \n",
       "0   MZ1-MZ010B  \n",
       "1   MZ1-MZ010Q  \n",
       "2   MZ1-MZ011B  \n",
       "3   MZ1-MZ011Q  \n",
       "4   MZ1-MZ012B  \n",
       "5   MZ1-MZ012Q  \n",
       "6   MZ1-MZ013B  "
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a journal line item per item per warehouse, with a replenishment_qty that is 100x the sum of order quantities (Cases) per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this dataframe before dropping columns not needed for order creation\n",
    "stock_journal = df5[['D365_ItemNo', 'D365_Del_Loc','Cases']]\n",
    "stock_journal = stock_journal.groupby(['D365_Del_Loc', 'D365_ItemNo'],as_index=False).sum('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D365_Del_Loc</th>\n",
       "      <th>D365_ItemNo</th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MZ1-MZ010B</td>\n",
       "      <td>1040</td>\n",
       "      <td>5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MZ1-MZ010B</td>\n",
       "      <td>1285</td>\n",
       "      <td>4556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MZ1-MZ010B</td>\n",
       "      <td>1463</td>\n",
       "      <td>2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MZ1-MZ010B</td>\n",
       "      <td>1480</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MZ1-MZ010B</td>\n",
       "      <td>1569</td>\n",
       "      <td>2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>MZ1-MZ013B</td>\n",
       "      <td>10926</td>\n",
       "      <td>2641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>MZ1-MZ013B</td>\n",
       "      <td>10927</td>\n",
       "      <td>1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>MZ1-MZ013B</td>\n",
       "      <td>11041</td>\n",
       "      <td>2686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>MZ1-MZ013B</td>\n",
       "      <td>11171</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>MZ1-MZ013B</td>\n",
       "      <td>11172</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    D365_Del_Loc  D365_ItemNo  Cases\n",
       "0     MZ1-MZ010B         1040   5187\n",
       "1     MZ1-MZ010B         1285   4556\n",
       "2     MZ1-MZ010B         1463   2673\n",
       "3     MZ1-MZ010B         1480   1659\n",
       "4     MZ1-MZ010B         1569   2661\n",
       "..           ...          ...    ...\n",
       "779   MZ1-MZ013B        10926   2641\n",
       "780   MZ1-MZ013B        10927   1605\n",
       "781   MZ1-MZ013B        11041   2686\n",
       "782   MZ1-MZ013B        11171   1830\n",
       "783   MZ1-MZ013B        11172   1073\n",
       "\n",
       "[784 rows x 3 columns]"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['replenishment_qty'] = stock_journal['Cases']*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with warehouse dataframe to get Financial Dimensions per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['INVENTORYSTATUSID'] = 'Available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "    stock_journal,\n",
    "    warehouses,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='D365_Del_Loc',\n",
    "    right_on='D365_Del_Loc',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1.rename(columns={'Financial_Dimension': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 784 entries, 0 to 783\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   D365_Del_Loc         784 non-null    object\n",
      " 1   D365_ItemNo          784 non-null    int64 \n",
      " 2   Cases                784 non-null    int64 \n",
      " 3   replenishment_qty    784 non-null    int64 \n",
      " 4   INVENTORYSTATUSID    784 non-null    object\n",
      " 5   site_id              784 non-null    object\n",
      " 6   WAREHOUSELOCATIONID  784 non-null    object\n",
      " 7   D365_WH_NO           784 non-null    object\n",
      " 8   FINANCIALDIMENSION   784 non-null    object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 55.2+ KB\n"
     ]
    }
   ],
   "source": [
    "stock_journal1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_journal1.drop(columns={'Cases', 'D365_WH_NAME', 'SAP_WH_NAME','Cost_Centre'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = stock_journal1.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    D365_Del_Loc  D365_ItemNo  Cases  replenishment_qty INVENTORYSTATUSID  \\\n",
      "0     MZ1-MZ010B         1040   5187             518700         Available   \n",
      "81    MZ1-MZ010B        10078   3754             375400         Available   \n",
      "80    MZ1-MZ010B        10077   1838             183800         Available   \n",
      "79    MZ1-MZ010B        10073   5347             534700         Available   \n",
      "78    MZ1-MZ010B        10072   2530             253000         Available   \n",
      "..           ...          ...    ...                ...               ...   \n",
      "702   MZ1-MZ013B         4996   8600             860000         Available   \n",
      "701   MZ1-MZ013B         4995   2600             260000         Available   \n",
      "699   MZ1-MZ013B         4769   9164             916400         Available   \n",
      "726   MZ1-MZ013B         6109   1342             134200         Available   \n",
      "783   MZ1-MZ013B        11172   1073             107300         Available   \n",
      "\n",
      "    site_id WAREHOUSELOCATIONID D365_WH_NO              FINANCIALDIMENSION  \n",
      "0     MZ010               GEN01     MZ010B  -BU01-MZ1F004--MZ1L004--MZ010-  \n",
      "81    MZ010               GEN01     MZ010B  -BU01-MZ1F004--MZ1L004--MZ010-  \n",
      "80    MZ010               GEN01     MZ010B  -BU01-MZ1F004--MZ1L004--MZ010-  \n",
      "79    MZ010               GEN01     MZ010B  -BU01-MZ1F004--MZ1L004--MZ010-  \n",
      "78    MZ010               GEN01     MZ010B  -BU01-MZ1F004--MZ1L004--MZ010-  \n",
      "..      ...                 ...        ...                             ...  \n",
      "702   MZ013               GEN01     MZ013B         -BU01-MZ1F004----MZ013-  \n",
      "701   MZ013               GEN01     MZ013B         -BU01-MZ1F004----MZ013-  \n",
      "699   MZ013               GEN01     MZ013B         -BU01-MZ1F004----MZ013-  \n",
      "726   MZ013               GEN01     MZ013B         -BU01-MZ1F004----MZ013-  \n",
      "783   MZ013               GEN01     MZ013B         -BU01-MZ1F004----MZ013-  \n",
      "\n",
      "[784 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_journal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a sequential index for LineNumber\n",
    "line_number = range(1,stock_journal1.last_valid_index()+2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock_journal1['LINENUMBER']=line_number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a journal number per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = pd.DataFrame(stock_journal1['D365_WH_NO'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number.rename(columns={0: 'D365_WH_NO'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = journal_number.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_valid_jnumber = input('Enter first valid journal number (numbers only)')\n",
    "#first_valid_jnumber = '76517'\n",
    "first_valid_jnumber = int(first_valid_jnumber)\n",
    "#ZA10700076636 - 24 Jan 2023\n",
    "#ZA10700084774 - 14 Mar\n",
    "# 2 Oct 2023\n",
    "# NA1-000031\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(first_valid_jnumber,first_valid_jnumber+journal_number.last_valid_index()+1,1)\n",
    "journal_number['JOURNALNUMBER']=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number['journal_str'] = journal_number['JOURNALNUMBER'].apply(lambda x: str(x).zfill(6))\n",
    "#journal_number['JOURNALNUMBER'] = journal_number['JOURNALNUMBER'].astype(str)\n",
    "journal_number['journal_str'] = LE + '-' + journal_number['journal_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "   stock_journal1,\n",
    "   journal_number,\n",
    "   how=\"inner\",\n",
    "   on=None,\n",
    "   left_on='D365_WH_NO',\n",
    "   right_on='D365_WH_NO',\n",
    "   left_index=False,\n",
    "   right_index=False,\n",
    "   sort=True,\n",
    "   suffixes=(\"_x\", \"_y\"),\n",
    "   copy=True,\n",
    "   indicator=False,\n",
    "   validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1['ITEMBATCHNUMBER']='1'\n",
    "stock_journal1['JOURNALNAMEID']='ADJ_WHS'\n",
    "stock_journal1['TRANSACTIONDATE']= pd.to_datetime('today').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/' + LE + '/stock_journal_' + LE + '.csv'\n",
    "stock_journal1.to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = df5[['D365_ItemNo', 'Material_Description']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112 entries, 119142 to 701152\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           112 non-null    int64 \n",
      " 1   Material_Description  112 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.6+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_items.to_excel('data/unique_items.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 427241 entries, 119142 to 209929\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   ActivityType              427241 non-null  object        \n",
      " 1   Order Number              427241 non-null  int64         \n",
      " 2   BaseDate                  427241 non-null  datetime64[ns]\n",
      " 3   BaseHour                  427241 non-null  int64         \n",
      " 4   Cases                     427241 non-null  int64         \n",
      " 5   Bill I                    424385 non-null  object        \n",
      " 6   Source Channel            427241 non-null  object        \n",
      " 7   Order Category            427241 non-null  object        \n",
      " 8   Material No               427241 non-null  object        \n",
      " 9   MOD                       427241 non-null  int64         \n",
      " 10  WAREHOUSELOCATIONID       427241 non-null  object        \n",
      " 11  CIC Order Placement Rule  427241 non-null  object        \n",
      " 12  D365_Account_Name         427241 non-null  object        \n",
      " 13  D365_Del_Loc              427241 non-null  object        \n",
      " 14  D365_ItemNo               427241 non-null  int64         \n",
      " 15  Material_Description      427241 non-null  object        \n",
      " 16  D365_Cust_No              427241 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(10)\n",
      "memory usage: 58.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   site_id              7 non-null      object\n",
      " 1   WAREHOUSELOCATIONID  7 non-null      object\n",
      " 2   D365_WH_NO           7 non-null      object\n",
      " 3   FINANCIALDIMENSION   7 non-null      object\n",
      " 4   D365_Del_Loc         7 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 408.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "warehouses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Cartesian product\n",
    "price_update = unique_items.assign(key=1).merge(warehouses.assign(key=1), on='key').drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 784 entries, 0 to 783\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           784 non-null    int64 \n",
      " 1   Material_Description  784 non-null    object\n",
      " 2   site_id               784 non-null    object\n",
      " 3   WAREHOUSELOCATIONID   784 non-null    object\n",
      " 4   D365_WH_NO            784 non-null    object\n",
      " 5   FINANCIALDIMENSION    784 non-null    object\n",
      " 6   D365_Del_Loc          784 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 43.0+ KB\n"
     ]
    }
   ],
   "source": [
    "price_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_update.drop(columns={'Material_Description', 'SAP_WH_NAME', 'D365_WH_NAME', 'D365_WH_NO', 'WAREHOUSELOCATIONID', 'Cost_Centre', 'Financial_Dimension', 'D365_Del_Loc'}, inplace=True, axis=1)\n",
    "price_update.drop(columns={'Material_Description', 'D365_WH_NO', 'WAREHOUSELOCATIONID', 'D365_Del_Loc'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update.rename(columns={'D365_ItemNo': 'ItemNumber', 'site_id': 'PriceSiteId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update = price_update.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update['Price'] = 42285\n",
    "price_update['PriceQuantity'] = 1000\n",
    "price_update['PriceType'] = 'Cost'\n",
    "price_update['CostingVersion'] = 'Std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_update.to_excel('output/price_update.xlsx',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
