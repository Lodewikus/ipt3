{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import SAP data previously mapped for ZA1\n",
    "\n",
    "15Dec_D365_orders_ZA1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5 = pd.read_csv(\"./data/ZA1/15Dec_D365_orders_ZA1.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data for other Legal Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = input('Enter the legal entity company code')\n",
    "# NA1, MZ1, UG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'+ LE + '/15Dec_D365_orders_' + LE + '.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_feather(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 370721 entries, 105098 to 182777\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   ActivityType              370721 non-null  object        \n",
      " 1   Order Number              370721 non-null  int64         \n",
      " 2   BaseDate                  370721 non-null  datetime64[ns]\n",
      " 3   BaseHour                  370721 non-null  int64         \n",
      " 4   Cases                     370721 non-null  int64         \n",
      " 5   Bill I                    368347 non-null  object        \n",
      " 6   Source Channel            370721 non-null  object        \n",
      " 7   Order Category            370721 non-null  object        \n",
      " 8   Material No               370721 non-null  object        \n",
      " 9   MOD                       370721 non-null  int64         \n",
      " 10  WAREHOUSELOCATIONID       370721 non-null  object        \n",
      " 11  CIC Order Placement Rule  370721 non-null  object        \n",
      " 12  D365_Account_Name         370721 non-null  object        \n",
      " 13  D365_Del_Loc              370721 non-null  object        \n",
      " 14  D365_ItemNo               370721 non-null  int64         \n",
      " 15  Material_Description      370721 non-null  object        \n",
      " 16  D365_Cust_No              370721 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(10)\n",
      "memory usage: 50.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.drop(columns={'Cases'}, inplace=True, axis=1)\n",
    "df5['Cases'] = np.random.randint(1, 4290, size=len(df5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/' + LE + '/15Dec_D365_orders_' + LE + '.csv'\n",
    "df5.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CSVs per activity type, and for the 13th and 20th hours\n",
    "# 1ORDERCREATION\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 12))\n",
    "peak_order_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_12h_' + LE + '.csv'\n",
    "peak_order_hour.to_csv(path,index=False)\n",
    "\n",
    "mask = ((df5['ActivityType'] == '1ORDERCREATION') &  (df5['BaseHour'] == 19))\n",
    "peak_settlement_hour = df5[mask]\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_1ORDERCREATION_19h_' + LE + '.csv'\n",
    "peak_settlement_hour.to_csv('output/15Dec_D365_orders_1ORDERCREATION_19h.csv',index=False)\n",
    "\n",
    "\n",
    "# 2PLAN - 12H\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4PLAN - 12H\n",
    "df5_1['MOD'] = '4'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4PLAN_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 2PLAN - 19H\n",
    "mask = ((df5['ActivityType'] == '2PLAN') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_2PLAN_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4PLAN - 19H\n",
    "df5_1['MOD'] = '4'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4PLAN_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 3DESPATCH\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "mask = ((df5['ActivityType'] == '3DESPATCH') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_3DESPATCH_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "# 4SETTLE - 12H\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5SETTLE - 12H\n",
    "df5_1['MOD'] = '5'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5SETTLE_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 4SETTLE - 19H\n",
    "mask = ((df5['ActivityType'] == '4SETTLE') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_4SETTLE_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5SETTLE - 19H\n",
    "df5_1['MOD'] = '5'\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5SETTLE_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "# 5TRADERETURNS\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 12))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_12h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "mask = ((df5['ActivityType'] == '5TRADERETURNS') &  (df5['BaseHour'] == 19))\n",
    "df5_1 = df5[mask].copy()\n",
    "df5_1.drop(columns={'CIC Order Placement Rule'}, inplace=True, axis=1)\n",
    "path = 'output/' + LE + '/15Dec_D365_orders_5TRADERETURNS_19h_' + LE + '.csv'\n",
    "df5_1.to_csv(path,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = peak_order_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "x.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a CSV for the rest of the hours, that is, excluding the 13th and 20th hours.  This set can be used to do preparation testing.\n",
    "mask = ((df5['BaseHour'] != 12) & (df5['BaseHour'] != 19))\n",
    "df5_1 = df5[mask]\n",
    "df5_1.to_csv('output/15Dec_D365_orders_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = peak_settlement_hour.groupby(['Source Channel']).agg({'Order Number': 'nunique','D365_ItemNo': 'count'}).reset_index()\n",
    "y.rename(columns={'D365_ItemNo': 'Order lines', 'Order Number': 'Sales orders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From above, generate a file that contains just one record per customer, so that we can use this to verify that each customer master record works\n",
    "df5_2 = df5_1.drop_duplicates(subset=['D365_Cust_No'],keep='first').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f5_2.to_csv('output/15Dec_D365_single_line_per_customer_excluding_12h_19h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise SystemExit(\"File generation completed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create file for stock journals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import warehouse files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LE == 'NA1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/NA1/NA1_Validated  IPT3 Warehouse Export  NA1 Warehouses.csv\", delimiter=\",\")\n",
    "    LE_Warehouses.rename(columns={'D365_Del_Location': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'WAREHOUSEID': 'D365_WH_NO', 'OPERATIONALSITEID': 'site_id', 'CCBWMSLOCATIONIDDEFAULTRECEIPT': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'CCBWAREHOUSETYPE', 'CCBFINANCECOSTCENTER', 'AREADVANCEDWAREHOUSEMANAGEMENTPROCESSESENABLED', 'D365_WH_NAME', 'CCBWAREHOUSECOSTCENTER'}, inplace=True, axis=1)\n",
    "    #D365_Del_Location\n",
    "\n",
    "if LE == 'MZ1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/MZ1/IPT3 MZ1 PERF01 Warehouse.csv\", delimiter=\",\")\n",
    "    LE_Warehouses.rename(columns={'D365DELIVERYLOCATION': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'WAREHOUSEID': 'D365_WH_NO', 'OPERATIONALSITEID': 'site_id', 'CCBWMSLOCATIONIDDEFAULTRECEIPT': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'CCBWAREHOUSETYPE', 'CCBFINANCECOSTCENTER', 'AREADVANCEDWAREHOUSEMANAGEMENTPROCESSESENABLED', 'D365WHNAME', 'CCBWAREHOUSECOSTCENTER'}, inplace=True, axis=1)\n",
    "if LE == 'UG1':\n",
    "    LE_Warehouses = pd.read_csv(\"./data/UG1/IPT3 WMS UG1-Warehouses.csv\", delimiter=\",\")    \n",
    "    LE_Warehouses.rename(columns={'D365_Del_Loc': 'D365_Del_Loc'}, inplace=True)\n",
    "    LE_Warehouses.rename(columns={'Warehouse': 'D365_WH_NO', 'Site ID': 'site_id', 'Location': 'WAREHOUSELOCATIONID', 'Financial Dimensions': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)\n",
    "    LE_Warehouses.drop(columns={'FinanceCost centre', 'Cost Centre'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warehouses = LE_Warehouses.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   D365_WH_NO           6 non-null      object\n",
      " 1   Unnamed: 1           6 non-null      object\n",
      " 2   site_id              6 non-null      object\n",
      " 3   WAREHOUSELOCATIONID  6 non-null      object\n",
      " 4   Financial_Dimension  6 non-null      object\n",
      " 5   D365_Del_Loc         6 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 416.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "warehouses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D365_WH_NO</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>site_id</th>\n",
       "      <th>WAREHOUSELOCATIONID</th>\n",
       "      <th>Financial_Dimension</th>\n",
       "      <th>D365_Del_Loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UG010B</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG010</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F005--UG1L015--UG010-</td>\n",
       "      <td>UG1-UG010B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UG010Q</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG010</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F005--UG1L015--UG010-</td>\n",
       "      <td>UG1-UG010Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UG011B</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG011</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F003--UG1L008--UG011-</td>\n",
       "      <td>UG1-UG011B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UG011Q</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG011</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F003--UG1L008--UG011-</td>\n",
       "      <td>UG1-UG011Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UG012B</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG012</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F003--UG1L003--UG012-</td>\n",
       "      <td>UG1-UG012B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UG012Q</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UG012</td>\n",
       "      <td>GEN01</td>\n",
       "      <td>-BU01-UG1F003--UG1L003--UG012-</td>\n",
       "      <td>UG1-UG012Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  D365_WH_NO Unnamed: 1 site_id WAREHOUSELOCATIONID  \\\n",
       "0     UG010B        Yes   UG010               GEN01   \n",
       "1     UG010Q        Yes   UG010               GEN01   \n",
       "2     UG011B        Yes   UG011               GEN01   \n",
       "3     UG011Q        Yes   UG011               GEN01   \n",
       "4     UG012B        Yes   UG012               GEN01   \n",
       "5     UG012Q        Yes   UG012               GEN01   \n",
       "\n",
       "              Financial_Dimension D365_Del_Loc  \n",
       "0  -BU01-UG1F005--UG1L015--UG010-   UG1-UG010B  \n",
       "1  -BU01-UG1F005--UG1L015--UG010-   UG1-UG010Q  \n",
       "2  -BU01-UG1F003--UG1L008--UG011-   UG1-UG011B  \n",
       "3  -BU01-UG1F003--UG1L008--UG011-   UG1-UG011Q  \n",
       "4  -BU01-UG1F003--UG1L003--UG012-   UG1-UG012B  \n",
       "5  -BU01-UG1F003--UG1L003--UG012-   UG1-UG012Q  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warehouses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a journal line item per item per warehouse, with a replenishment_qty that is 100x the sum of order quantities (Cases) per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this dataframe before dropping columns not needed for order creation\n",
    "stock_journal = df5[['D365_ItemNo', 'D365_Del_Loc','Cases']]\n",
    "stock_journal = stock_journal.groupby(['D365_Del_Loc', 'D365_ItemNo'],as_index=False).sum('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D365_Del_Loc</th>\n",
       "      <th>D365_ItemNo</th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1010</td>\n",
       "      <td>1531665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1040</td>\n",
       "      <td>2031207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1062</td>\n",
       "      <td>1006661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1108</td>\n",
       "      <td>1728750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UG1-UG010B</td>\n",
       "      <td>1271</td>\n",
       "      <td>4030822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>UG1-UG012Q</td>\n",
       "      <td>11135</td>\n",
       "      <td>927443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>UG1-UG012Q</td>\n",
       "      <td>11136</td>\n",
       "      <td>1948780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>UG1-UG012Q</td>\n",
       "      <td>11137</td>\n",
       "      <td>1149671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>UG1-UG012Q</td>\n",
       "      <td>11165</td>\n",
       "      <td>698303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>UG1-UG012Q</td>\n",
       "      <td>11166</td>\n",
       "      <td>524864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    D365_Del_Loc  D365_ItemNo    Cases\n",
       "0     UG1-UG010B         1010  1531665\n",
       "1     UG1-UG010B         1040  2031207\n",
       "2     UG1-UG010B         1062  1006661\n",
       "3     UG1-UG010B         1108  1728750\n",
       "4     UG1-UG010B         1271  4030822\n",
       "..           ...          ...      ...\n",
       "481   UG1-UG012Q        11135   927443\n",
       "482   UG1-UG012Q        11136  1948780\n",
       "483   UG1-UG012Q        11137  1149671\n",
       "484   UG1-UG012Q        11165   698303\n",
       "485   UG1-UG012Q        11166   524864\n",
       "\n",
       "[486 rows x 3 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['replenishment_qty'] = stock_journal['Cases']*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with warehouse dataframe to get Financial Dimensions per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal['INVENTORYSTATUSID'] = 'Available'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "    stock_journal,\n",
    "    warehouses,\n",
    "    how=\"inner\",\n",
    "    on=None,\n",
    "    left_on='D365_Del_Loc',\n",
    "    right_on='D365_Del_Loc',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1.rename(columns={'Financial_Dimension': 'DEFAULTLEDGERDIMENSIONDISPLAYVALUE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486 entries, 0 to 485\n",
      "Data columns (total 10 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   D365_Del_Loc                        486 non-null    object\n",
      " 1   D365_ItemNo                         486 non-null    int64 \n",
      " 2   Cases                               486 non-null    int64 \n",
      " 3   replenishment_qty                   486 non-null    int64 \n",
      " 4   INVENTORYSTATUSID                   486 non-null    object\n",
      " 5   D365_WH_NO                          486 non-null    object\n",
      " 6   Unnamed: 1                          486 non-null    object\n",
      " 7   site_id                             486 non-null    object\n",
      " 8   WAREHOUSELOCATIONID                 486 non-null    object\n",
      " 9   DEFAULTLEDGERDIMENSIONDISPLAYVALUE  486 non-null    object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 38.1+ KB\n"
     ]
    }
   ],
   "source": [
    "stock_journal1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_journal1.drop(columns={'Cases', 'D365_WH_NAME', 'SAP_WH_NAME','Cost_Centre'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = stock_journal1.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    D365_Del_Loc  D365_ItemNo    Cases  replenishment_qty INVENTORYSTATUSID  \\\n",
      "0     UG1-UG010B         1010  1531665          153166500         Available   \n",
      "58    UG1-UG010B        10314  1638177          163817700         Available   \n",
      "57    UG1-UG010B        10306  2745383          274538300         Available   \n",
      "56    UG1-UG010B        10208  4263790          426379000         Available   \n",
      "55    UG1-UG010B        10082   717020           71702000         Available   \n",
      "..           ...          ...      ...                ...               ...   \n",
      "428   UG1-UG012Q         3040  1193057          119305700         Available   \n",
      "427   UG1-UG012Q         3010   995415           99541500         Available   \n",
      "426   UG1-UG012Q         2376  1481420          148142000         Available   \n",
      "423   UG1-UG012Q         2204  1318484          131848400         Available   \n",
      "485   UG1-UG012Q        11166   524864           52486400         Available   \n",
      "\n",
      "    D365_WH_NO Unnamed: 1 site_id WAREHOUSELOCATIONID  \\\n",
      "0       UG010B        Yes   UG010               GEN01   \n",
      "58      UG010B        Yes   UG010               GEN01   \n",
      "57      UG010B        Yes   UG010               GEN01   \n",
      "56      UG010B        Yes   UG010               GEN01   \n",
      "55      UG010B        Yes   UG010               GEN01   \n",
      "..         ...        ...     ...                 ...   \n",
      "428     UG012Q        Yes   UG012               GEN01   \n",
      "427     UG012Q        Yes   UG012               GEN01   \n",
      "426     UG012Q        Yes   UG012               GEN01   \n",
      "423     UG012Q        Yes   UG012               GEN01   \n",
      "485     UG012Q        Yes   UG012               GEN01   \n",
      "\n",
      "    DEFAULTLEDGERDIMENSIONDISPLAYVALUE  \n",
      "0       -BU01-UG1F005--UG1L015--UG010-  \n",
      "58      -BU01-UG1F005--UG1L015--UG010-  \n",
      "57      -BU01-UG1F005--UG1L015--UG010-  \n",
      "56      -BU01-UG1F005--UG1L015--UG010-  \n",
      "55      -BU01-UG1F005--UG1L015--UG010-  \n",
      "..                                 ...  \n",
      "428     -BU01-UG1F003--UG1L003--UG012-  \n",
      "427     -BU01-UG1F003--UG1L003--UG012-  \n",
      "426     -BU01-UG1F003--UG1L003--UG012-  \n",
      "423     -BU01-UG1F003--UG1L003--UG012-  \n",
      "485     -BU01-UG1F003--UG1L003--UG012-  \n",
      "\n",
      "[486 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_journal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a sequential index for LineNumber\n",
    "line_number = range(1,stock_journal1.last_valid_index()+2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stock_journal1['LINENUMBER']=line_number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a journal number per warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = pd.DataFrame(stock_journal1['D365_WH_NO'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number.rename(columns={0: 'D365_WH_NO'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number = journal_number.sort_values(['D365_WH_NO'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_valid_jnumber = input('Enter first valid journal number (numbers only)')\n",
    "#first_valid_jnumber = '76517'\n",
    "first_valid_jnumber = int(first_valid_jnumber)\n",
    "#ZA10700076636 - 24 Jan 2023\n",
    "#ZA10700084774 - 14 Mar\n",
    "# 2 Oct 2023\n",
    "# NA1-000031\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(first_valid_jnumber,first_valid_jnumber+journal_number.last_valid_index()+1,1)\n",
    "journal_number['JOURNALNUMBER']=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_number['journal_str'] = journal_number['JOURNALNUMBER'].apply(lambda x: str(x).zfill(6))\n",
    "#journal_number['JOURNALNUMBER'] = journal_number['JOURNALNUMBER'].astype(str)\n",
    "journal_number['journal_str'] = LE + '-' + journal_number['journal_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1 = pd.merge(\n",
    "   stock_journal1,\n",
    "   journal_number,\n",
    "   how=\"inner\",\n",
    "   on=None,\n",
    "   left_on='D365_WH_NO',\n",
    "   right_on='D365_WH_NO',\n",
    "   left_index=False,\n",
    "   right_index=False,\n",
    "   sort=True,\n",
    "   suffixes=(\"_x\", \"_y\"),\n",
    "   copy=True,\n",
    "   indicator=False,\n",
    "   validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_journal1['ITEMBATCHNUMBER']='1'\n",
    "stock_journal1['JOURNALNAMEID']='ADJ_WHS'\n",
    "stock_journal1['TRANSACTIONDATE']= pd.to_datetime('today').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'output/' + LE + '/stock_journal_' + LE + '.csv'\n",
    "stock_journal1.to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = df5[['D365_ItemNo', 'Material_Description']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 81 entries, 105098 to 607902\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           81 non-null     int64 \n",
      " 1   Material_Description  81 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_items.to_excel('data/unique_items.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 370721 entries, 105098 to 182777\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   ActivityType              370721 non-null  object        \n",
      " 1   Order Number              370721 non-null  int64         \n",
      " 2   BaseDate                  370721 non-null  datetime64[ns]\n",
      " 3   BaseHour                  370721 non-null  int64         \n",
      " 4   Bill I                    368347 non-null  object        \n",
      " 5   Source Channel            370721 non-null  object        \n",
      " 6   Order Category            370721 non-null  object        \n",
      " 7   Material No               370721 non-null  object        \n",
      " 8   MOD                       370721 non-null  int64         \n",
      " 9   WAREHOUSELOCATIONID       370721 non-null  object        \n",
      " 10  CIC Order Placement Rule  370721 non-null  object        \n",
      " 11  D365_Account_Name         370721 non-null  object        \n",
      " 12  D365_Del_Loc              370721 non-null  object        \n",
      " 13  D365_ItemNo               370721 non-null  int64         \n",
      " 14  Material_Description      370721 non-null  object        \n",
      " 15  D365_Cust_No              370721 non-null  int64         \n",
      " 16  Cases                     370721 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(10)\n",
      "memory usage: 50.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   D365_WH_NO           6 non-null      object\n",
      " 1   Unnamed: 1           6 non-null      object\n",
      " 2   site_id              6 non-null      object\n",
      " 3   WAREHOUSELOCATIONID  6 non-null      object\n",
      " 4   Financial_Dimension  6 non-null      object\n",
      " 5   D365_Del_Loc         6 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 416.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "warehouses.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Cartesian product\n",
    "price_update = unique_items.assign(key=1).merge(warehouses.assign(key=1), on='key').drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486 entries, 0 to 485\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   D365_ItemNo           486 non-null    int64 \n",
      " 1   Material_Description  486 non-null    object\n",
      " 2   D365_WH_NO            486 non-null    object\n",
      " 3   Unnamed: 1            486 non-null    object\n",
      " 4   site_id               486 non-null    object\n",
      " 5   WAREHOUSELOCATIONID   486 non-null    object\n",
      " 6   Financial_Dimension   486 non-null    object\n",
      " 7   D365_Del_Loc          486 non-null    object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 30.5+ KB\n"
     ]
    }
   ],
   "source": [
    "price_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_update.drop(columns={'Material_Description', 'SAP_WH_NAME', 'D365_WH_NAME', 'D365_WH_NO', 'WAREHOUSELOCATIONID', 'Cost_Centre', 'Financial_Dimension', 'D365_Del_Loc'}, inplace=True, axis=1)\n",
    "price_update.drop(columns={'Material_Description', 'D365_WH_NO', 'WAREHOUSELOCATIONID', 'D365_Del_Loc'}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update.rename(columns={'D365_ItemNo': 'ItemNumber', 'site_id': 'PriceSiteId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update = price_update.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_update['Price'] = 42285\n",
    "price_update['PriceQuantity'] = 1000\n",
    "price_update['PriceType'] = 'Cost'\n",
    "price_update['CostingVersion'] = 'Std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_update.to_excel('output/price_update.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
